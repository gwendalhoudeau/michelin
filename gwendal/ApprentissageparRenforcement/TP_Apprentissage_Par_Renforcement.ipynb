{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c1a7274",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Mise-en-place-de-l'environnement\" data-toc-modified-id=\"Mise-en-place-de-l'environnement-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Mise en place de l'environnement</a></span><ul class=\"toc-item\"><li><span><a href=\"#Test-de-l'Environnement\" data-toc-modified-id=\"Test-de-l'Environnement-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Test de l'Environnement</a></span></li></ul></li><li><span><a href=\"#Implémentation-de-l'Algorithme-Deep-Deterministic-Policy-Gradient-(DDPG)\" data-toc-modified-id=\"Implémentation-de-l'Algorithme-Deep-Deterministic-Policy-Gradient-(DDPG)-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Implémentation de l'Algorithme Deep Deterministic Policy Gradient (DDPG)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Création-de-l'Acteur\" data-toc-modified-id=\"Création-de-l'Acteur-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Création de l'Acteur</a></span></li><li><span><a href=\"#Création-du-Critique\" data-toc-modified-id=\"Création-du-Critique-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Création du Critique</a></span></li><li><span><a href=\"#Création-du-Générateur-de-Bruit\" data-toc-modified-id=\"Création-du-Générateur-de-Bruit-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Création du Générateur de Bruit</a></span></li><li><span><a href=\"#Gestion-de-l'Experience-Replay\" data-toc-modified-id=\"Gestion-de-l'Experience-Replay-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Gestion de l'Experience Replay</a></span></li><li><span><a href=\"#Mise-à-jour-des-réseaux-cibles\" data-toc-modified-id=\"Mise-à-jour-des-réseaux-cibles-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Mise à jour des réseaux cibles</a></span></li><li><span><a href=\"#Apprentissage\" data-toc-modified-id=\"Apprentissage-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Apprentissage</a></span></li><li><span><a href=\"#Diagnostique\" data-toc-modified-id=\"Diagnostique-2.7\"><span class=\"toc-item-num\">2.7&nbsp;&nbsp;</span>Diagnostique</a></span></li><li><span><a href=\"#Réglage-des-paramètres-d'apprentissage\" data-toc-modified-id=\"Réglage-des-paramètres-d'apprentissage-2.8\"><span class=\"toc-item-num\">2.8&nbsp;&nbsp;</span>Réglage des paramètres d'apprentissage</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e86dbb",
   "metadata": {},
   "source": [
    "Les modèles (physiques ou corrélatifs) des pneumatiques jouent un rôle essentiel dans la mise au points de scénarios de conception ainsi que dans l'évaluation des performances des nouvelles gammes ou de gammes existantes. Ainsi, le modèle de rigidité de dérive vu dans le TP portant sur l'Optimisation Bayesienne, peut être exploité à travers des chaines de simulation pour juger de la qualité de pneumatiques en terme de critère de comportement, d'adhérence, d'endurance ou encore de temps au tour. C'est à cette performance que nous allons nous intéresser ici.\n",
    "\n",
    "Plus précisément, l'exercice consiste à mettre en place un environnement de simulation basé sur de l'apprentissage par renforcement qui a pour objectif de trouver les controles optimaux à appliquer à un véhicule pour que ce dernier puisse parcourir un circuit circulaire avec la vitesse la plus élevée possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5a940b",
   "metadata": {},
   "source": [
    "## Mise en place de l'environnement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1130e4ac",
   "metadata": {},
   "source": [
    "En l'occurence, les états que l'on va considérer pour notre environnement sont:\n",
    "- $x$: position du véhicule selon la direction $\\vec{X}$\n",
    "- $y$: position du véhicule selon la direction $\\vec{Y}$\n",
    "- $\\psi$: l'angle de lacet du véhicule\n",
    "- $\\dot{x}$: vitesse du véhicule selon la direction $\\vec{X}$\n",
    "- $\\dot{y}$: vitesse du véhicule selon la direction $\\vec{Y}$\n",
    "- $\\dot{\\psi}$: vitesse de lacet du véhicule\n",
    "\n",
    "Les actions qui seront utilisées sont:\n",
    "- $v$: la vitesse\n",
    "- $\\alpha$: l'angle de braquage\n",
    "\n",
    "L'environnement que l'on va exploiter s'appuie sur le package Gym de la société OpenAI (https://gym.openai.com/). Un tel environnement s'appuie sur l'utilisation d'objets héritant de la classe *gym.Env* et comportant les méthodes suivantes:\n",
    "- **__init__**: constructeur définissant les expaces d'actions (*action_space*) et d'observations (*observation_space*)\n",
    "- **reset**: méthode permettant de réinitialiser les états\n",
    "- **step**: fonction qui prend en entrée les valeurs des actions et renvoie les nouveaux états de l'environnement, le reward ainsi qu'un booléen indiquant s'il est nécessaire de réinitialiser les états \n",
    "- **render**: méthode qui affiche l'état de l'environnement et différentes informations le concernant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c5d6cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "from gym_gmmcar.envs.circle_env import CircleEnv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2984f0",
   "metadata": {},
   "source": [
    "Notre objectif étant de rester sur le cirucuit tout en allant le plus vite possible, quel(-s) reward(-s) peut-on envisager? Implémenter l'un d'entre eux en complétant la méthode *get_reward* de la classe *OttEnv* ci-dessous:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5589fb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OttEnv(CircleEnv):\n",
    "    \"\"\"\n",
    "    Environnement de simulation pour une voiture de course suivant une trajectoire circulaire aussi vite que possible\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            target_velocity=1.0,\n",
    "            radius=1.0,\n",
    "            dt=0.035,\n",
    "            model_type='BrushTireModel',\n",
    "            robot_type='RCCar',\n",
    "            mu_s=1.37,\n",
    "            mu_k=1.96,\n",
    "            eps=0.05\n",
    "    ):\n",
    "\n",
    "        super().__init__(\n",
    "            target_velocity=target_velocity,\n",
    "            radius=radius,\n",
    "            dt=dt,\n",
    "            model_type=model_type,\n",
    "            robot_type=robot_type,\n",
    "            mu_s=mu_s,\n",
    "            mu_k=mu_k\n",
    "        )\n",
    "\n",
    "        self.eps = eps\n",
    "\n",
    "\n",
    "    def get_reward(self, state, action):\n",
    "        \"\"\"\n",
    "        Définition de la fonction de Reward\n",
    "        \"\"\"\n",
    "        r = self.radius\n",
    "        x, y, _, x_dot, y_dot, _ = state\n",
    "        vitesse = np.sqrt(x_dot**2 + y_dot**2)\n",
    "        distance = np.sqrt(x**2 + y**2) - r\n",
    "\n",
    "        # Reward à définir\n",
    "        \n",
    "        distance_reward = abs(distance)\n",
    "        vitesse_reward = vitesse\n",
    "        reward = vitesse_reward - distance_reward\n",
    "        \n",
    "        \n",
    "        info = {}\n",
    "        info['dist'] = distance\n",
    "        info['vel'] = vitesse\n",
    "        return reward, info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fed2b78",
   "metadata": {},
   "source": [
    "### Test de l'Environnement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3c92cd",
   "metadata": {},
   "source": [
    "Tester l'environnement en considérant un épisode de 100 pas de temps et des actions aléatoires et/ou fixes. Pour ce faire, compléter le script ci-dessous en définissant les actions à appliquer à chaque pas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a18d5d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\E087262\\AppData\\Local\\miniconda3\\envs\\michelin2\\lib\\site-packages\\gym\\spaces\\box.py:127: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"
     ]
    },
    {
     "data": {
      "application/javascript": "/* Put everything inside the global mpl namespace */\n/* global mpl */\nwindow.mpl = {};\n\nmpl.get_websocket_type = function () {\n    if (typeof WebSocket !== 'undefined') {\n        return WebSocket;\n    } else if (typeof MozWebSocket !== 'undefined') {\n        return MozWebSocket;\n    } else {\n        alert(\n            'Your browser does not have WebSocket support. ' +\n                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n                'Firefox 4 and 5 are also supported but you ' +\n                'have to enable WebSockets in about:config.'\n        );\n    }\n};\n\nmpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n    this.id = figure_id;\n\n    this.ws = websocket;\n\n    this.supports_binary = this.ws.binaryType !== undefined;\n\n    if (!this.supports_binary) {\n        var warnings = document.getElementById('mpl-warnings');\n        if (warnings) {\n            warnings.style.display = 'block';\n            warnings.textContent =\n                'This browser does not support binary websocket messages. ' +\n                'Performance may be slow.';\n        }\n    }\n\n    this.imageObj = new Image();\n\n    this.context = undefined;\n    this.message = undefined;\n    this.canvas = undefined;\n    this.rubberband_canvas = undefined;\n    this.rubberband_context = undefined;\n    this.format_dropdown = undefined;\n\n    this.image_mode = 'full';\n\n    this.root = document.createElement('div');\n    this.root.setAttribute('style', 'display: inline-block');\n    this._root_extra_style(this.root);\n\n    parent_element.appendChild(this.root);\n\n    this._init_header(this);\n    this._init_canvas(this);\n    this._init_toolbar(this);\n\n    var fig = this;\n\n    this.waiting = false;\n\n    this.ws.onopen = function () {\n        fig.send_message('supports_binary', { value: fig.supports_binary });\n        fig.send_message('send_image_mode', {});\n        if (fig.ratio !== 1) {\n            fig.send_message('set_device_pixel_ratio', {\n                device_pixel_ratio: fig.ratio,\n            });\n        }\n        fig.send_message('refresh', {});\n    };\n\n    this.imageObj.onload = function () {\n        if (fig.image_mode === 'full') {\n            // Full images could contain transparency (where diff images\n            // almost always do), so we need to clear the canvas so that\n            // there is no ghosting.\n            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n        }\n        fig.context.drawImage(fig.imageObj, 0, 0);\n    };\n\n    this.imageObj.onunload = function () {\n        fig.ws.close();\n    };\n\n    this.ws.onmessage = this._make_on_message_function(this);\n\n    this.ondownload = ondownload;\n};\n\nmpl.figure.prototype._init_header = function () {\n    var titlebar = document.createElement('div');\n    titlebar.classList =\n        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n    var titletext = document.createElement('div');\n    titletext.classList = 'ui-dialog-title';\n    titletext.setAttribute(\n        'style',\n        'width: 100%; text-align: center; padding: 3px;'\n    );\n    titlebar.appendChild(titletext);\n    this.root.appendChild(titlebar);\n    this.header = titletext;\n};\n\nmpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n\nmpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n\nmpl.figure.prototype._init_canvas = function () {\n    var fig = this;\n\n    var canvas_div = (this.canvas_div = document.createElement('div'));\n    canvas_div.setAttribute(\n        'style',\n        'border: 1px solid #ddd;' +\n            'box-sizing: content-box;' +\n            'clear: both;' +\n            'min-height: 1px;' +\n            'min-width: 1px;' +\n            'outline: 0;' +\n            'overflow: hidden;' +\n            'position: relative;' +\n            'resize: both;'\n    );\n\n    function on_keyboard_event_closure(name) {\n        return function (event) {\n            return fig.key_event(event, name);\n        };\n    }\n\n    canvas_div.addEventListener(\n        'keydown',\n        on_keyboard_event_closure('key_press')\n    );\n    canvas_div.addEventListener(\n        'keyup',\n        on_keyboard_event_closure('key_release')\n    );\n\n    this._canvas_extra_style(canvas_div);\n    this.root.appendChild(canvas_div);\n\n    var canvas = (this.canvas = document.createElement('canvas'));\n    canvas.classList.add('mpl-canvas');\n    canvas.setAttribute('style', 'box-sizing: content-box;');\n\n    this.context = canvas.getContext('2d');\n\n    var backingStore =\n        this.context.backingStorePixelRatio ||\n        this.context.webkitBackingStorePixelRatio ||\n        this.context.mozBackingStorePixelRatio ||\n        this.context.msBackingStorePixelRatio ||\n        this.context.oBackingStorePixelRatio ||\n        this.context.backingStorePixelRatio ||\n        1;\n\n    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n\n    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n        'canvas'\n    ));\n    rubberband_canvas.setAttribute(\n        'style',\n        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n    );\n\n    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n    if (this.ResizeObserver === undefined) {\n        if (window.ResizeObserver !== undefined) {\n            this.ResizeObserver = window.ResizeObserver;\n        } else {\n            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n            this.ResizeObserver = obs.ResizeObserver;\n        }\n    }\n\n    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n        var nentries = entries.length;\n        for (var i = 0; i < nentries; i++) {\n            var entry = entries[i];\n            var width, height;\n            if (entry.contentBoxSize) {\n                if (entry.contentBoxSize instanceof Array) {\n                    // Chrome 84 implements new version of spec.\n                    width = entry.contentBoxSize[0].inlineSize;\n                    height = entry.contentBoxSize[0].blockSize;\n                } else {\n                    // Firefox implements old version of spec.\n                    width = entry.contentBoxSize.inlineSize;\n                    height = entry.contentBoxSize.blockSize;\n                }\n            } else {\n                // Chrome <84 implements even older version of spec.\n                width = entry.contentRect.width;\n                height = entry.contentRect.height;\n            }\n\n            // Keep the size of the canvas and rubber band canvas in sync with\n            // the canvas container.\n            if (entry.devicePixelContentBoxSize) {\n                // Chrome 84 implements new version of spec.\n                canvas.setAttribute(\n                    'width',\n                    entry.devicePixelContentBoxSize[0].inlineSize\n                );\n                canvas.setAttribute(\n                    'height',\n                    entry.devicePixelContentBoxSize[0].blockSize\n                );\n            } else {\n                canvas.setAttribute('width', width * fig.ratio);\n                canvas.setAttribute('height', height * fig.ratio);\n            }\n            canvas.setAttribute(\n                'style',\n                'width: ' + width + 'px; height: ' + height + 'px;'\n            );\n\n            rubberband_canvas.setAttribute('width', width);\n            rubberband_canvas.setAttribute('height', height);\n\n            // And update the size in Python. We ignore the initial 0/0 size\n            // that occurs as the element is placed into the DOM, which should\n            // otherwise not happen due to the minimum size styling.\n            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n                fig.request_resize(width, height);\n            }\n        }\n    });\n    this.resizeObserverInstance.observe(canvas_div);\n\n    function on_mouse_event_closure(name) {\n        return function (event) {\n            return fig.mouse_event(event, name);\n        };\n    }\n\n    rubberband_canvas.addEventListener(\n        'mousedown',\n        on_mouse_event_closure('button_press')\n    );\n    rubberband_canvas.addEventListener(\n        'mouseup',\n        on_mouse_event_closure('button_release')\n    );\n    rubberband_canvas.addEventListener(\n        'dblclick',\n        on_mouse_event_closure('dblclick')\n    );\n    // Throttle sequential mouse events to 1 every 20ms.\n    rubberband_canvas.addEventListener(\n        'mousemove',\n        on_mouse_event_closure('motion_notify')\n    );\n\n    rubberband_canvas.addEventListener(\n        'mouseenter',\n        on_mouse_event_closure('figure_enter')\n    );\n    rubberband_canvas.addEventListener(\n        'mouseleave',\n        on_mouse_event_closure('figure_leave')\n    );\n\n    canvas_div.addEventListener('wheel', function (event) {\n        if (event.deltaY < 0) {\n            event.step = 1;\n        } else {\n            event.step = -1;\n        }\n        on_mouse_event_closure('scroll')(event);\n    });\n\n    canvas_div.appendChild(canvas);\n    canvas_div.appendChild(rubberband_canvas);\n\n    this.rubberband_context = rubberband_canvas.getContext('2d');\n    this.rubberband_context.strokeStyle = '#000000';\n\n    this._resize_canvas = function (width, height, forward) {\n        if (forward) {\n            canvas_div.style.width = width + 'px';\n            canvas_div.style.height = height + 'px';\n        }\n    };\n\n    // Disable right mouse context menu.\n    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n        event.preventDefault();\n        return false;\n    });\n\n    function set_focus() {\n        canvas.focus();\n        canvas_div.focus();\n    }\n\n    window.setTimeout(set_focus, 100);\n};\n\nmpl.figure.prototype._init_toolbar = function () {\n    var fig = this;\n\n    var toolbar = document.createElement('div');\n    toolbar.classList = 'mpl-toolbar';\n    this.root.appendChild(toolbar);\n\n    function on_click_closure(name) {\n        return function (_event) {\n            return fig.toolbar_button_onclick(name);\n        };\n    }\n\n    function on_mouseover_closure(tooltip) {\n        return function (event) {\n            if (!event.currentTarget.disabled) {\n                return fig.toolbar_button_onmouseover(tooltip);\n            }\n        };\n    }\n\n    fig.buttons = {};\n    var buttonGroup = document.createElement('div');\n    buttonGroup.classList = 'mpl-button-group';\n    for (var toolbar_ind in mpl.toolbar_items) {\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) {\n            /* Instead of a spacer, we start a new button group. */\n            if (buttonGroup.hasChildNodes()) {\n                toolbar.appendChild(buttonGroup);\n            }\n            buttonGroup = document.createElement('div');\n            buttonGroup.classList = 'mpl-button-group';\n            continue;\n        }\n\n        var button = (fig.buttons[name] = document.createElement('button'));\n        button.classList = 'mpl-widget';\n        button.setAttribute('role', 'button');\n        button.setAttribute('aria-disabled', 'false');\n        button.addEventListener('click', on_click_closure(method_name));\n        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n\n        var icon_img = document.createElement('img');\n        icon_img.src = '_images/' + image + '.png';\n        icon_img.srcset = '_images/' + image + '_large.png 2x';\n        icon_img.alt = tooltip;\n        button.appendChild(icon_img);\n\n        buttonGroup.appendChild(button);\n    }\n\n    if (buttonGroup.hasChildNodes()) {\n        toolbar.appendChild(buttonGroup);\n    }\n\n    var fmt_picker = document.createElement('select');\n    fmt_picker.classList = 'mpl-widget';\n    toolbar.appendChild(fmt_picker);\n    this.format_dropdown = fmt_picker;\n\n    for (var ind in mpl.extensions) {\n        var fmt = mpl.extensions[ind];\n        var option = document.createElement('option');\n        option.selected = fmt === mpl.default_extension;\n        option.innerHTML = fmt;\n        fmt_picker.appendChild(option);\n    }\n\n    var status_bar = document.createElement('span');\n    status_bar.classList = 'mpl-message';\n    toolbar.appendChild(status_bar);\n    this.message = status_bar;\n};\n\nmpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n    // which will in turn request a refresh of the image.\n    this.send_message('resize', { width: x_pixels, height: y_pixels });\n};\n\nmpl.figure.prototype.send_message = function (type, properties) {\n    properties['type'] = type;\n    properties['figure_id'] = this.id;\n    this.ws.send(JSON.stringify(properties));\n};\n\nmpl.figure.prototype.send_draw_message = function () {\n    if (!this.waiting) {\n        this.waiting = true;\n        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n    }\n};\n\nmpl.figure.prototype.handle_save = function (fig, _msg) {\n    var format_dropdown = fig.format_dropdown;\n    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n    fig.ondownload(fig, format);\n};\n\nmpl.figure.prototype.handle_resize = function (fig, msg) {\n    var size = msg['size'];\n    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n        fig._resize_canvas(size[0], size[1], msg['forward']);\n        fig.send_message('refresh', {});\n    }\n};\n\nmpl.figure.prototype.handle_rubberband = function (fig, msg) {\n    var x0 = msg['x0'] / fig.ratio;\n    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n    var x1 = msg['x1'] / fig.ratio;\n    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n    x0 = Math.floor(x0) + 0.5;\n    y0 = Math.floor(y0) + 0.5;\n    x1 = Math.floor(x1) + 0.5;\n    y1 = Math.floor(y1) + 0.5;\n    var min_x = Math.min(x0, x1);\n    var min_y = Math.min(y0, y1);\n    var width = Math.abs(x1 - x0);\n    var height = Math.abs(y1 - y0);\n\n    fig.rubberband_context.clearRect(\n        0,\n        0,\n        fig.canvas.width / fig.ratio,\n        fig.canvas.height / fig.ratio\n    );\n\n    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n};\n\nmpl.figure.prototype.handle_figure_label = function (fig, msg) {\n    // Updates the figure title.\n    fig.header.textContent = msg['label'];\n};\n\nmpl.figure.prototype.handle_cursor = function (fig, msg) {\n    fig.rubberband_canvas.style.cursor = msg['cursor'];\n};\n\nmpl.figure.prototype.handle_message = function (fig, msg) {\n    fig.message.textContent = msg['message'];\n};\n\nmpl.figure.prototype.handle_draw = function (fig, _msg) {\n    // Request the server to send over a new figure.\n    fig.send_draw_message();\n};\n\nmpl.figure.prototype.handle_image_mode = function (fig, msg) {\n    fig.image_mode = msg['mode'];\n};\n\nmpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n    for (var key in msg) {\n        if (!(key in fig.buttons)) {\n            continue;\n        }\n        fig.buttons[key].disabled = !msg[key];\n        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n    }\n};\n\nmpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n    if (msg['mode'] === 'PAN') {\n        fig.buttons['Pan'].classList.add('active');\n        fig.buttons['Zoom'].classList.remove('active');\n    } else if (msg['mode'] === 'ZOOM') {\n        fig.buttons['Pan'].classList.remove('active');\n        fig.buttons['Zoom'].classList.add('active');\n    } else {\n        fig.buttons['Pan'].classList.remove('active');\n        fig.buttons['Zoom'].classList.remove('active');\n    }\n};\n\nmpl.figure.prototype.updated_canvas_event = function () {\n    // Called whenever the canvas gets updated.\n    this.send_message('ack', {});\n};\n\n// A function to construct a web socket function for onmessage handling.\n// Called in the figure constructor.\nmpl.figure.prototype._make_on_message_function = function (fig) {\n    return function socket_on_message(evt) {\n        if (evt.data instanceof Blob) {\n            var img = evt.data;\n            if (img.type !== 'image/png') {\n                /* FIXME: We get \"Resource interpreted as Image but\n                 * transferred with MIME type text/plain:\" errors on\n                 * Chrome.  But how to set the MIME type?  It doesn't seem\n                 * to be part of the websocket stream */\n                img.type = 'image/png';\n            }\n\n            /* Free the memory for the previous frames */\n            if (fig.imageObj.src) {\n                (window.URL || window.webkitURL).revokeObjectURL(\n                    fig.imageObj.src\n                );\n            }\n\n            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n                img\n            );\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        } else if (\n            typeof evt.data === 'string' &&\n            evt.data.slice(0, 21) === 'data:image/png;base64'\n        ) {\n            fig.imageObj.src = evt.data;\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        }\n\n        var msg = JSON.parse(evt.data);\n        var msg_type = msg['type'];\n\n        // Call the  \"handle_{type}\" callback, which takes\n        // the figure and JSON message as its only arguments.\n        try {\n            var callback = fig['handle_' + msg_type];\n        } catch (e) {\n            console.log(\n                \"No handler for the '\" + msg_type + \"' message type: \",\n                msg\n            );\n            return;\n        }\n\n        if (callback) {\n            try {\n                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n                callback(fig, msg);\n            } catch (e) {\n                console.log(\n                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n                    e,\n                    e.stack,\n                    msg\n                );\n            }\n        }\n    };\n};\n\n// from https://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\nmpl.findpos = function (e) {\n    //this section is from http://www.quirksmode.org/js/events_properties.html\n    var targ;\n    if (!e) {\n        e = window.event;\n    }\n    if (e.target) {\n        targ = e.target;\n    } else if (e.srcElement) {\n        targ = e.srcElement;\n    }\n    if (targ.nodeType === 3) {\n        // defeat Safari bug\n        targ = targ.parentNode;\n    }\n\n    // pageX,Y are the mouse positions relative to the document\n    var boundingRect = targ.getBoundingClientRect();\n    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n\n    return { x: x, y: y };\n};\n\n/*\n * return a copy of an object with only non-object keys\n * we need this to avoid circular references\n * https://stackoverflow.com/a/24161582/3208463\n */\nfunction simpleKeys(original) {\n    return Object.keys(original).reduce(function (obj, key) {\n        if (typeof original[key] !== 'object') {\n            obj[key] = original[key];\n        }\n        return obj;\n    }, {});\n}\n\nmpl.figure.prototype.mouse_event = function (event, name) {\n    var canvas_pos = mpl.findpos(event);\n\n    if (name === 'button_press') {\n        this.canvas.focus();\n        this.canvas_div.focus();\n    }\n\n    var x = canvas_pos.x * this.ratio;\n    var y = canvas_pos.y * this.ratio;\n\n    this.send_message(name, {\n        x: x,\n        y: y,\n        button: event.button,\n        step: event.step,\n        guiEvent: simpleKeys(event),\n    });\n\n    /* This prevents the web browser from automatically changing to\n     * the text insertion cursor when the button is pressed.  We want\n     * to control all of the cursor setting manually through the\n     * 'cursor' event from matplotlib */\n    event.preventDefault();\n    return false;\n};\n\nmpl.figure.prototype._key_event_extra = function (_event, _name) {\n    // Handle any extra behaviour associated with a key event\n};\n\nmpl.figure.prototype.key_event = function (event, name) {\n    // Prevent repeat events\n    if (name === 'key_press') {\n        if (event.key === this._key) {\n            return;\n        } else {\n            this._key = event.key;\n        }\n    }\n    if (name === 'key_release') {\n        this._key = null;\n    }\n\n    var value = '';\n    if (event.ctrlKey && event.key !== 'Control') {\n        value += 'ctrl+';\n    }\n    else if (event.altKey && event.key !== 'Alt') {\n        value += 'alt+';\n    }\n    else if (event.shiftKey && event.key !== 'Shift') {\n        value += 'shift+';\n    }\n\n    value += 'k' + event.key;\n\n    this._key_event_extra(event, name);\n\n    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n    return false;\n};\n\nmpl.figure.prototype.toolbar_button_onclick = function (name) {\n    if (name === 'download') {\n        this.handle_save(this, null);\n    } else {\n        this.send_message('toolbar_button', { name: name });\n    }\n};\n\nmpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n    this.message.textContent = tooltip;\n};\n\n///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n// prettier-ignore\nvar _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\nmpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n\nmpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n\nmpl.default_extension = \"png\";/* global mpl */\n\nvar comm_websocket_adapter = function (comm) {\n    // Create a \"websocket\"-like object which calls the given IPython comm\n    // object with the appropriate methods. Currently this is a non binary\n    // socket, so there is still some room for performance tuning.\n    var ws = {};\n\n    ws.binaryType = comm.kernel.ws.binaryType;\n    ws.readyState = comm.kernel.ws.readyState;\n    function updateReadyState(_event) {\n        if (comm.kernel.ws) {\n            ws.readyState = comm.kernel.ws.readyState;\n        } else {\n            ws.readyState = 3; // Closed state.\n        }\n    }\n    comm.kernel.ws.addEventListener('open', updateReadyState);\n    comm.kernel.ws.addEventListener('close', updateReadyState);\n    comm.kernel.ws.addEventListener('error', updateReadyState);\n\n    ws.close = function () {\n        comm.close();\n    };\n    ws.send = function (m) {\n        //console.log('sending', m);\n        comm.send(m);\n    };\n    // Register the callback with on_msg.\n    comm.on_msg(function (msg) {\n        //console.log('receiving', msg['content']['data'], msg);\n        var data = msg['content']['data'];\n        if (data['blob'] !== undefined) {\n            data = {\n                data: new Blob(msg['buffers'], { type: data['blob'] }),\n            };\n        }\n        // Pass the mpl event to the overridden (by mpl) onmessage function.\n        ws.onmessage(data);\n    });\n    return ws;\n};\n\nmpl.mpl_figure_comm = function (comm, msg) {\n    // This is the function which gets called when the mpl process\n    // starts-up an IPython Comm through the \"matplotlib\" channel.\n\n    var id = msg.content.data.id;\n    // Get hold of the div created by the display call when the Comm\n    // socket was opened in Python.\n    var element = document.getElementById(id);\n    var ws_proxy = comm_websocket_adapter(comm);\n\n    function ondownload(figure, _format) {\n        window.open(figure.canvas.toDataURL());\n    }\n\n    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n\n    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n    // web socket which is closed, not our websocket->open comm proxy.\n    ws_proxy.onopen();\n\n    fig.parent_element = element;\n    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n    if (!fig.cell_info) {\n        console.error('Failed to find cell for figure', id, fig);\n        return;\n    }\n    fig.cell_info[0].output_area.element.on(\n        'cleared',\n        { fig: fig },\n        fig._remove_fig_handler\n    );\n};\n\nmpl.figure.prototype.handle_close = function (fig, msg) {\n    var width = fig.canvas.width / fig.ratio;\n    fig.cell_info[0].output_area.element.off(\n        'cleared',\n        fig._remove_fig_handler\n    );\n    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n\n    // Update the output cell to use the data from the current canvas.\n    fig.push_to_output();\n    var dataURL = fig.canvas.toDataURL();\n    // Re-enable the keyboard manager in IPython - without this line, in FF,\n    // the notebook keyboard shortcuts fail.\n    IPython.keyboard_manager.enable();\n    fig.parent_element.innerHTML =\n        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n    fig.close_ws(fig, msg);\n};\n\nmpl.figure.prototype.close_ws = function (fig, msg) {\n    fig.send_message('closing', msg);\n    // fig.ws.close()\n};\n\nmpl.figure.prototype.push_to_output = function (_remove_interactive) {\n    // Turn the data on the canvas into data in the output cell.\n    var width = this.canvas.width / this.ratio;\n    var dataURL = this.canvas.toDataURL();\n    this.cell_info[1]['text/html'] =\n        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n};\n\nmpl.figure.prototype.updated_canvas_event = function () {\n    // Tell IPython that the notebook contents must change.\n    IPython.notebook.set_dirty(true);\n    this.send_message('ack', {});\n    var fig = this;\n    // Wait a second, then push the new image to the DOM so\n    // that it is saved nicely (might be nice to debounce this).\n    setTimeout(function () {\n        fig.push_to_output();\n    }, 1000);\n};\n\nmpl.figure.prototype._init_toolbar = function () {\n    var fig = this;\n\n    var toolbar = document.createElement('div');\n    toolbar.classList = 'btn-toolbar';\n    this.root.appendChild(toolbar);\n\n    function on_click_closure(name) {\n        return function (_event) {\n            return fig.toolbar_button_onclick(name);\n        };\n    }\n\n    function on_mouseover_closure(tooltip) {\n        return function (event) {\n            if (!event.currentTarget.disabled) {\n                return fig.toolbar_button_onmouseover(tooltip);\n            }\n        };\n    }\n\n    fig.buttons = {};\n    var buttonGroup = document.createElement('div');\n    buttonGroup.classList = 'btn-group';\n    var button;\n    for (var toolbar_ind in mpl.toolbar_items) {\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) {\n            /* Instead of a spacer, we start a new button group. */\n            if (buttonGroup.hasChildNodes()) {\n                toolbar.appendChild(buttonGroup);\n            }\n            buttonGroup = document.createElement('div');\n            buttonGroup.classList = 'btn-group';\n            continue;\n        }\n\n        button = fig.buttons[name] = document.createElement('button');\n        button.classList = 'btn btn-default';\n        button.href = '#';\n        button.title = name;\n        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n        button.addEventListener('click', on_click_closure(method_name));\n        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n        buttonGroup.appendChild(button);\n    }\n\n    if (buttonGroup.hasChildNodes()) {\n        toolbar.appendChild(buttonGroup);\n    }\n\n    // Add the status bar.\n    var status_bar = document.createElement('span');\n    status_bar.classList = 'mpl-message pull-right';\n    toolbar.appendChild(status_bar);\n    this.message = status_bar;\n\n    // Add the close button to the window.\n    var buttongrp = document.createElement('div');\n    buttongrp.classList = 'btn-group inline pull-right';\n    button = document.createElement('button');\n    button.classList = 'btn btn-mini btn-primary';\n    button.href = '#';\n    button.title = 'Stop Interaction';\n    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n    button.addEventListener('click', function (_evt) {\n        fig.handle_close(fig, {});\n    });\n    button.addEventListener(\n        'mouseover',\n        on_mouseover_closure('Stop Interaction')\n    );\n    buttongrp.appendChild(button);\n    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n};\n\nmpl.figure.prototype._remove_fig_handler = function (event) {\n    var fig = event.data.fig;\n    if (event.target !== this) {\n        // Ignore bubbled events from children.\n        return;\n    }\n    fig.close_ws(fig, {});\n};\n\nmpl.figure.prototype._root_extra_style = function (el) {\n    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n};\n\nmpl.figure.prototype._canvas_extra_style = function (el) {\n    // this is important to make the div 'focusable\n    el.setAttribute('tabindex', 0);\n    // reach out to IPython and tell the keyboard manager to turn it's self\n    // off when our div gets focus\n\n    // location in version 3\n    if (IPython.notebook.keyboard_manager) {\n        IPython.notebook.keyboard_manager.register_events(el);\n    } else {\n        // location in version 2\n        IPython.keyboard_manager.register_events(el);\n    }\n};\n\nmpl.figure.prototype._key_event_extra = function (event, _name) {\n    // Check for shift+enter\n    if (event.shiftKey && event.which === 13) {\n        this.canvas_div.blur();\n        // select the cell after this one\n        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n        IPython.notebook.select(index + 1);\n    }\n};\n\nmpl.figure.prototype.handle_save = function (fig, _msg) {\n    fig.ondownload(fig, null);\n};\n\nmpl.find_output_cell = function (html_output) {\n    // Return the cell and output element which can be found *uniquely* in the notebook.\n    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n    // IPython event is triggered only after the cells have been serialised, which for\n    // our purposes (turning an active figure into a static one), is too late.\n    var cells = IPython.notebook.get_cells();\n    var ncells = cells.length;\n    for (var i = 0; i < ncells; i++) {\n        var cell = cells[i];\n        if (cell.cell_type === 'code') {\n            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n                var data = cell.output_area.outputs[j];\n                if (data.data) {\n                    // IPython >= 3 moved mimebundle to data attribute of output\n                    data = data.data;\n                }\n                if (data['text/html'] === html_output) {\n                    return [cell, data, j];\n                }\n            }\n        }\n    }\n};\n\n// Register the function which deals with the matplotlib target/channel.\n// The kernel may be null if the page has been refreshed.\nif (IPython.notebook.kernel !== null) {\n    IPython.notebook.kernel.comm_manager.register_target(\n        'matplotlib',\n        mpl.mpl_figure_comm\n    );\n}\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id='c11387b8-6588-4249-aa58-efd64c9b854d'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.13900746  0.17088742 -1.04768807  0.28354916]\n"
     ]
    }
   ],
   "source": [
    "env = OttEnv()\n",
    "obs = env.reset()\n",
    "print(env.observation_space.shape[0])\n",
    "env.render()\n",
    "\n",
    "\n",
    "episode = 1\n",
    "for step in range(100):\n",
    "    #action = np.array([1.0, 0.0])\n",
    "    action = np.random.uniform(low=-1.0, high=1.0, size=(2,))\n",
    "    # Mettre une valeur random sur les action, pour tester : OK\n",
    "    new_state, reward, done, info = env.step(action)\n",
    "    env.render()\n",
    "    \n",
    "print(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efff82c",
   "metadata": {},
   "source": [
    "Etant donné les caractéristiques du problème considéré, quel type de méthode devrait-on appliquer?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefea573",
   "metadata": {},
   "source": [
    "## Implémentation de l'Algorithme Deep Deterministic Policy Gradient (DDPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16ad190",
   "metadata": {},
   "source": [
    "Pour tenter de trouver les commandes optimales à appliquer, nous allons ici utiliser une approche DDPG. Pour ce faire, la première étape à réaliser est d'implémenter cette méthode en s'appuyant sur le pseudo-code suivant vu en cours:\n",
    "![DDPG.png](DDPG.png \"Algorithme DDPG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d06dda",
   "metadata": {},
   "source": [
    "### Création de l'Acteur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d82702",
   "metadata": {},
   "source": [
    "Pour rappel, l'acteur a pour objectif d'estimer un politique $\\mu(s_{t})$. Dans un premier temps, créer un acteur à partir d'une fonction ou d'une classe en définissant un modèle neuronal tensorflow ayant l'architecture suivante:\n",
    "- une première couche cachée dense comportant 256 neurones et une fonction d'activation de type RELU\n",
    "- une seconde couche cachée dense comportant 256 neurones et une fonction d'activation de type RELU\n",
    "- une couche de sortie dense comportant un nombre de neurones égal au nombre d'actions et une fonction d'activation de type tanh\n",
    "\n",
    "<ins>**Remarque:**</ins> Les sorties étant bornées entre -1 et 1, ne pas oublier de dénormaliser pour générer des valeurs d'actions conformes à l'espace des actions.\n",
    "<ins>**Conseil:**</ins> Pour pouvoir tester différentes architectures par la suite, paramétrer les couches à l'aide d'une variable indiquant le nombre de neurones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d40be15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc5bece5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition de l'acteur \n",
    "\n",
    "def actor(nb_neurones,nb_action=2,dim_entry_etat=6):\n",
    "    \n",
    "    x0 = Input(shape=(dim_entry_etat,))\n",
    "    x1 = tf.keras.layers.Dense(nb_neurones,activation='relu')(x0)\n",
    "    x2 = tf.keras.layers.Dense(nb_neurones, activation='relu')(x1)\n",
    "\n",
    "    ## si besoin de normalisation\n",
    "    #x2_normalized = tf.keras.layers.BatchNormalization()(x2)\n",
    "    \n",
    "    #x3 = Dense(nb_action, activation='tanh')(x2_normalized)\n",
    "\n",
    "    x3 = tf.keras.layers.Dense(nb_action, activation='tanh')(x2)\n",
    "    \n",
    "    actor = Model(inputs=x0, outputs=x3)\n",
    "    \n",
    "    return actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ba11734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test :\n",
    "A=actor(256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f7508c",
   "metadata": {},
   "source": [
    "### Création du Critique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3482374",
   "metadata": {},
   "source": [
    "Pour rappel, le critique a pour objectif d'estimer la valeur $Q(s_{t},a_{t})$Dans un premier temps, créer un critique à partir d'une fonction ou d'une classe en définissant un modèle neuronal tensorflow de la manière suivante:\n",
    "- Créer un réseau prenant en entrée les états avec:\n",
    "  - une première couche cachée dense comportant 16 neurones et une fonction d'activation de type RELU\n",
    "  - une seconde couche cachée dense comportant 32 neurones et une fonction d'activation de type RELU\n",
    "- Créer un réseau prenant en entrée les actions avec une couche cachée dense comportant 32 neurones et une fonction d'activation de type RELU\n",
    "- Concaténer les sorties des 2 réseaux précédents via la méthode \"*Concatenate*\"\n",
    "- Créer un réseau prenant les entrées la concaténation des tenseurs précédents avec:\n",
    "  - une première couche cachée dense comportant 256 neurones et une fonction d'activation de type RELU\n",
    "  - une seconde couche cachée dense comportant 256 neurones et une fonction d'activation de type RELU\n",
    "  - une couche de sortie dense comportant 1 neurone sans fonction d'activation \n",
    "\n",
    "<ins>**Conseil:**</ins> Pour pouvoir tester différentes architectures par la suite, paramétrer les couches à l'aide d'une variable indiquant le nombre de neurones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64f5e7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f56d0670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition du critique\n",
    "\n",
    "\n",
    "def critic(nb_neurones_couches, dim_entry_etat=6, dim_entry_action=2):\n",
    "    \n",
    "    # Premier réseau avec les états\n",
    "    x0_1 = Input(shape=(dim_entry_etat,))\n",
    "    x1_1 = tf.keras.layers.Dense(nb_neurones_couches[0], activation='relu')(x0_1)\n",
    "    x2_1 = tf.keras.layers.Dense(nb_neurones_couches[1], activation='relu')(x1_1)\n",
    "    \n",
    "    # Deuxième réseau avec les actions\n",
    "    x0_2 = Input(shape=(dim_entry_action,))\n",
    "    x1_2 = tf.keras.layers.Dense(nb_neurones_couches[2], activation='relu')(x0_2)\n",
    "    \n",
    "    # Concaténation\n",
    "    x0_3 = concatenate([x2_1, x1_2])\n",
    "    \n",
    "    # Troisième Réseau\n",
    "    x1_3 = tf.keras.layers.Dense(nb_neurones_couches[3], activation='relu')(x0_3)\n",
    "    x2_3 = tf.keras.layers.Dense(nb_neurones_couches[4], activation='relu')(x1_3)\n",
    "    x3_3 = tf.keras.layers.Dense(1)(x2_3)\n",
    "    \n",
    "    critic = Model(inputs=[x0_1, x0_2], outputs=x3_3)\n",
    "    \n",
    "    return critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41fad3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_neurones=[16,32,32,256,256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2b32d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "C=critic(nb_neurones)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06becb5e",
   "metadata": {},
   "source": [
    "### Création du Générateur de Bruit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad7ce24",
   "metadata": {},
   "source": [
    "Comme précisé en cours, l'approche DDPG génère les actions de manière déterministe, ce qui engendre mécaniquement une démarche purement basée sur de l'exploitation. Pour éviter d'être coincé dans un optimum local, il est nécessaire d'appliquer une stratégie d'exploration. En l'occurrence, cette exploration est gérée via l'ajout d'un bruit à l'action générée par l'acteur.\n",
    "Ce bruit est généré via un processus stochastique de type ***Ornstein-Uhlenbeck*** défini par l'équation différentielle stochastique:\n",
    "\n",
    "$dx_{t}=\\theta(\\nu-x_{t})dt+\\sigma\\sqrt{d_{t}}u$ avec $u\\sim \\mathcal{N}(0,1)$\n",
    "\n",
    "Créer une fonction ou classe permettant de générer ce bruit avec $\\theta=0.15$ et $d_{t}=1e-2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46121e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition du génrateur de bruit\n",
    "\n",
    "def bruit(sigma,v,xt,teta=0.15,dt=1e-2):\n",
    "    \n",
    "    u=np.random.rand(2)\n",
    "    # 2 Car deux actions possibles \n",
    "     \n",
    "    dx=teta*(v-xt)*dt+sigma*np.sqrt(dt)*u\n",
    "    \n",
    "    return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcd2454",
   "metadata": {},
   "source": [
    "### Gestion de l'Experience Replay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c58d6db",
   "metadata": {},
   "source": [
    "Afin de ne pas oublier les expériences passées et réduire les corrélations entre expériences, un tirage aléatoire de $N$ tuples (état présent, action, reward, état suivant) stockés dans un buffer de taille $B$.\n",
    "Créer une fonction ou classe permettant de:\n",
    "- Initialiser un buffer de taille $B$ à 0\n",
    "- Sauvegarder à chaque pas de temps un 4-uplet (état présent, action, reward, état suivant)\n",
    "- Tirer aléatoirement $N$ tuples (état présent, action, reward, état suivant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "463c341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialisation_Replay(B):\n",
    "\n",
    "    Buffer=[]\n",
    "    for i in range(B):\n",
    "        liste=[[0,0,0,0],[0,0],0,[0,0,0,0,0,0]]\n",
    "\n",
    "        Buffer.append(liste)\n",
    "    \n",
    "\n",
    "    return Buffer\n",
    "# Ou faire en Matrice a voir\n",
    "\n",
    "def save_Replay(Buffer,present,action,reward,suivant,pas):\n",
    "\n",
    "    liste=[present,action,reward,suivant]\n",
    "    Buffer[pas]=liste\n",
    "    \n",
    "    return Buffer\n",
    "\n",
    "def tirage_Replay(Buffer,N,B):\n",
    "\n",
    "    nombre=[]\n",
    "    Tuples=[]\n",
    "\n",
    "    for i in range(N):\n",
    "\n",
    "        alea=np.random.randint(0,B)\n",
    "        nombre.append(alea)\n",
    "\n",
    "    for j in range(len(nombre)):\n",
    "\n",
    "        Tuples.append(Buffer[nombre[j]])\n",
    "\n",
    "    return Tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e0dd563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0, 0, 0, 0], [0, 0], 0, [0, 0, 0, 0, 0, 0]],\n",
       " [[0, 0, 0, 0], [0, 0], 0, [0, 0, 0, 0, 0, 0]],\n",
       " [[0, 0, 0, 0], [0, 0], 0, [0, 0, 0, 0, 0, 0]],\n",
       " [[0, 0, 0, 0], [0, 0], 0, [0, 0, 0, 0, 0, 0]],\n",
       " [[0, 0, 0, 0], [0, 0], 0, [0, 0, 0, 0, 0, 0]],\n",
       " [[0, 0, 0, 0], [0, 0], 0, [0, 0, 0, 0, 0, 0]],\n",
       " [[0, 0, 0, 0], [0, 0], 0, [0, 0, 0, 0, 0, 0]],\n",
       " [[0, 0, 0, 0], [0, 0], 0, [0, 0, 0, 0, 0, 0]],\n",
       " [[0, 0, 0, 0], [0, 0], 0, [0, 0, 0, 0, 0, 0]],\n",
       " [[0, 0, 0, 0], [0, 0], 0, [0, 0, 0, 0, 0, 0]]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test : Initialisation\n",
    "buffer=initialisation_Replay(10)\n",
    "buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5caf77b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0, 0, 0, 0], [0, 0], 0, [0, 0, 0, 0, 0, 0]],\n",
       " [[0, 0, 0, 0], [0, 0], 0, [0, 0, 0, 0, 0, 0]],\n",
       " [[0, 0, 0, 0], [0, 0], 0, [0, 0, 0, 0, 0, 0]],\n",
       " [[0, 0, 0, 0], [0, 0], 0, [0, 0, 0, 0, 0, 0]],\n",
       " [[10, 11, 12, 13, 14, 15], [5, 2], 12, [4, 5, 6, 7, 8, 9]],\n",
       " [[0, 0, 0, 0], [0, 0], 0, [0, 0, 0, 0, 0, 0]],\n",
       " [[0, 0, 0, 0], [0, 0], 0, [0, 0, 0, 0, 0, 0]],\n",
       " [[0, 0, 0, 0], [0, 0], 0, [0, 0, 0, 0, 0, 0]],\n",
       " [[0, 0, 0, 0], [0, 0], 0, [0, 0, 0, 0, 0, 0]],\n",
       " [[0, 0, 0, 0], [0, 0], 0, [0, 0, 0, 0, 0, 0]]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test : Sauvegarde\n",
    "\n",
    "buffer_save=save_Replay(buffer,[10,11,12,13,14,15],[5,2],12,[4,5,6,7,8,9],4)\n",
    "buffer_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d25228c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0, 0, 0, 0], [0, 0], 0, [0, 0, 0, 0, 0, 0]],\n",
       " [[0, 0, 0, 0], [0, 0], 0, [0, 0, 0, 0, 0, 0]]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test : Tirage\n",
    "\n",
    "T=tirage_Replay(buffer,2,10)\n",
    "T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18db96a2",
   "metadata": {},
   "source": [
    "### Mise à jour des réseaux cibles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed4148c",
   "metadata": {},
   "source": [
    "Comme présenté en cours, la gestion des cibles mouvantes se fait via la mise en place de réseaux cibles. En l'occurrence, deux réseaux cibles sont utilisés: l'un pour l'acteur et l'autre pour le critique.\n",
    "Créer une fonction ou classe qui mette à jour les poids des réseaux cibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc74a9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mise à jour des réseaux cibles\n",
    "\n",
    "def Mise_a_jour_crit(tau, critic_model, target_critic_model):\n",
    "    critic_weights = critic_model.get_weights()\n",
    "    target_critic_weights = target_critic_model.get_weights()\n",
    "    for i in range(len(critic_weights)):\n",
    "        target_critic_weights[i] = tau * critic_weights[i] + (1 - tau) * target_critic_weights[i]\n",
    "    target_critic_model.set_weights(target_critic_weights)\n",
    "\n",
    "    return target_critic_model\n",
    "\n",
    "def Mise_a_jour_acteur(tau, actor_model, target_actor_model):\n",
    "    actor_weights = actor_model.get_weights()\n",
    "    target_actor_weights = target_actor_model.get_weights()\n",
    "    for i in range(len(actor_weights)):\n",
    "        target_actor_weights[i] = tau * actor_weights[i] + (1 - tau) * target_actor_weights[i]\n",
    "    target_actor_model.set_weights(target_actor_weights)\n",
    "\n",
    "    return target_actor_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaa8330",
   "metadata": {},
   "source": [
    "### Apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cb8611",
   "metadata": {},
   "source": [
    "Utiliser l'ensembles des fonctions/classes précédemment construites pour implémenter l'apprentissage présenté par le pseudo-code apparaissant plus haut avec les paramètres suivants:\n",
    "- learning rate de l'acteur:0.002\n",
    "- learning rate du critique: 0.001\n",
    "- paramètre du générateur de bruit $\\sigma$: 0.2\n",
    "- paramètre du générateur de bruit $\\nu$: 0\n",
    "- nombre totale d'épisode $M$: 100\n",
    "- facteur d'escompte $\\gamma$: 0.99\n",
    "- paramètre mise à jour des réseaux cible $\\tau$: 0.005\n",
    "- taille du buffer $B$: 1000\n",
    "- taille $N$ des batchs: 100\n",
    "\n",
    "Pour pouvoir mener un diagnosqtique de l'apprentissage, stocker les rewards cumulés à la fin de chaque épisode dans une liste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd49c16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23c6dbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithme DDPG\n",
    "\n",
    "\n",
    "def DDPG(learning_acteur=0.002,learning_crit=0.001,bruit_sigma=0.2, bruit_v=0.0, M=100, f_escompte=0.99, tau=0.005, \n",
    "          B=1000, N=100):\n",
    "     \n",
    "\n",
    "     nb_neurones = 256\n",
    "     nb_neurones_couches = [16, 32, 32, 256, 256]\n",
    "     gamma = tf.cast(tf.constant(0.95),tf.float64)\n",
    "\n",
    "     # Initialisation des réseaux\n",
    "     A = actor(nb_neurones)\n",
    "     C = critic(nb_neurones_couches)\n",
    "     A_target = actor(nb_neurones)\n",
    "     C_target = critic(nb_neurones_couches)\n",
    "\n",
    "     # Initialisation des Optimizers\n",
    "     A_optimizer = Adam(learning_rate=0.001)\n",
    "     C_optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "     # Initialisation du replay buffer\n",
    "     Buffer = initialisation_Replay(B)\n",
    "\n",
    "     # Initialisation de l'environnement\n",
    "     env = OttEnv()\n",
    "\n",
    "     episode_rewards = []\n",
    "\n",
    "     T=3\n",
    "\n",
    "     for episode in range(M):\n",
    "          # Réinitialisation de l'environnement\n",
    "          state = env.reset()\n",
    "          total_reward = 0\n",
    "          state1 = np.array([-1.28179312, -0.03076161, 3.81707614, 1.61656511, -0.1866938, -0.35831151])\n",
    "          state = state1.reshape((1, 6))\n",
    "          for t in range(T):\n",
    "               print(episode,t)\n",
    "               print(state)\n",
    "               # Sélection de l'action avec le réseau d'acteur\n",
    "               action = A.predict(state.reshape(1, -1))[0] + bruit(bruit_sigma, bruit_v, A.predict(state.reshape(1, -1)))\n",
    "               # Exécution de l'action\n",
    "               next_state, reward, done, _ = env.step(action[0])\n",
    "\n",
    "               # Ajout de l'expérience au replay buffer\n",
    "               if done :\n",
    "                    Buffer = save_Replay(Buffer, state, action, reward, next_state, episode)\n",
    "               \n",
    "               # Tirage d'un batch d'expériences du replay buffer\n",
    "               batch = tirage_Replay(Buffer, N, B)\n",
    "               states, actions, rewards, next_states = zip(*batch)\n",
    "\n",
    "               states=tf.convert_to_tensor(states)\n",
    "               actions=tf.convert_to_tensor(actions)\n",
    "               rewards=tf.convert_to_tensor(rewards)\n",
    "               next_states=tf.convert_to_tensor(next_states)\n",
    "               print(rewards.shape)\n",
    "\n",
    "\n",
    "               # Calcul des cibles pour l'entraînement du critique\n",
    "               q_actions=A_target(next_states)\n",
    "               q_target=tf.cast(rewards,tf.float64) + (tf.cast(tf.constant(1.0),tf.float64)-tf.cast(done,tf.float64))*gamma*tf.cast(C_target([next_states,q_actions]),tf.float64)\n",
    "\n",
    "               # Entraînement du critique\n",
    "               with tf.GradientTape() as tape:\n",
    "                    current_q_value = C([next_states, actions])\n",
    "                    critic_loss = tf.reduce_mean(tf.math.pow(q_target-tf.cast(current_q_value,tf.float64),2))\n",
    "                    \n",
    "                    #critic_loss = tf.reduce_mean(tf.square(targets - C([np.array(next_states), np.array(actions)])))\n",
    "               \n",
    "               grads_critic = tape.gradient(critic_loss, C.trainable_variables)\n",
    "               C_optimizer.apply_gradients(zip(grads_critic, C.trainable_variables))\n",
    "\n",
    "               # Entraînement de l'acteur\n",
    "               with tf.GradientTape() as tape:\n",
    "                    actions = A(next_states,training=True)\n",
    "                    current_q_value = C([next_states,actions],training=True)\n",
    "                    actor_loss = -tf.reduce_mean(current_q_value)\n",
    "\n",
    "               grads_actor = tape.gradient(actor_loss, A.trainable_variables)\n",
    "               A_optimizer.apply_gradients(zip(grads_actor, A.trainable_variables))\n",
    "\n",
    "               # Mise à jour des réseaux cibles\n",
    "               A_target=Mise_a_jour_acteur(tau,A,A_target)\n",
    "               C_target=Mise_a_jour_acteur(tau,C,C_target)\n",
    "\n",
    "               total_reward += reward\n",
    "               state = next_state\n",
    "\n",
    "               if done:\n",
    "                    break\n",
    "          episode_rewards.append(total_reward)\n",
    "          print(f\"Épisode {episode + 1}/{M}, Reward cumulé: {total_reward}\")\n",
    "\n",
    "        \n",
    "     return episode_rewards\n",
    "     \n",
    "\n",
    "     \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d124c71",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "(100,)\n",
      "0 1\n",
      "[-1.21874618 -0.01468072  4.9576589   0.2903966  -0.05344174  0.10977893]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "0 2\n",
      "[-1.21732530e+00 -2.28126469e-02  4.95837121e+00  2.18635116e-01\n",
      " -4.72028362e-03 -3.31697872e-02]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "Épisode 1/100, Reward cumulé: 0.07862188946244361\n",
      "1 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "(100,)\n",
      "1 1\n",
      "[-1.18818943 -0.0072196   5.04692697  0.16816336 -0.05370836 -0.50781978]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n",
      "1 2\n",
      "[-1.18645728e+00 -1.37054703e-02  5.04195182e+00  1.93851377e-01\n",
      " -4.72653619e-03 -4.15939082e-02]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "Épisode 2/100, Reward cumulé: 0.024544384913593564\n",
      "2 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "2 1\n",
      "[-1.06870178 -0.05579456  4.87808026  1.47869035 -0.0752814  -0.24070419]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "2 2\n",
      "[-1.06353568 -0.10294801  4.86825933  1.22852765 -0.06408483 -0.30854814]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "(100,)\n",
      "Épisode 3/100, Reward cumulé: 3.4841682750856124\n",
      "3 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "(100,)\n",
      "3 1\n",
      "[-0.95522412 -0.03185014  3.84412655  1.66978353 -0.28424903  0.01238341]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "3 2\n",
      "[-1.00204433 -0.06032644  3.84844462  1.42238097 -0.21295876  0.2084046 ]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "(100,)\n",
      "Épisode 4/100, Reward cumulé: 4.223982081851227\n",
      "4 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "(100,)\n",
      "4 1\n",
      "[-1.04407471 -0.03821125  5.36316292  1.01040307 -0.23457995 -0.62719595]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "4 2\n",
      "[-1.02980952 -0.06653046  5.35126292  0.77171486 -0.10185302 -0.13288593]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "(100,)\n",
      "Épisode 5/100, Reward cumulé: 2.2485696371032238\n",
      "5 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "(100,)\n",
      "5 1\n",
      "[-1.07671917e+00  3.05981450e-03  3.71311032e+00  1.67004122e-01\n",
      " -8.78616753e-02 -7.93020226e-01]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "(100,)\n",
      "5 2\n",
      "[-1.08191561e+00  7.98903806e-04  3.70463526e+00  1.58012325e-01\n",
      " -4.90382696e-03 -4.33037189e-02]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "(100,)\n",
      "Épisode 6/100, Reward cumulé: 0.25949563105012463\n",
      "6 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "6 1\n",
      "[-0.83629923 -0.01536201  3.81994588  0.88677746 -0.20639023  0.53269204]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "(100,)\n",
      "6 2\n",
      "[-0.86046955 -0.02802035  3.84056928  0.63996999 -0.11983297  0.58425106]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "(100,)\n",
      "Épisode 7/100, Reward cumulé: 1.5377516081024358\n",
      "7 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "(100,)\n",
      "7 1\n",
      "[-1.14693766 -0.03282989  4.18056044  0.89047518  0.0361602   0.21210784]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "(100,)\n",
      "7 2\n",
      "[-1.16036648 -0.05595528  4.18097049  0.63887074 -0.01482978 -0.11043374]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "(100,)\n",
      "Épisode 8/100, Reward cumulé: 1.4441032664281641\n",
      "8 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "8 1\n",
      "[-1.11321883 -0.0238905   5.54585381  0.57165422 -0.24042226  1.21338093]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "8 2\n",
      "[-1.10477119 -0.03872304  5.58175902  0.35463739 -0.09156022  0.72462355]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "(100,)\n",
      "Épisode 9/100, Reward cumulé: 0.8971892572994596\n",
      "9 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "(100,)\n",
      "9 1\n",
      "[-1.17837316 -0.05506566  4.72695216  1.44210814  0.26305645  0.58863818]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "(100,)\n",
      "9 2\n",
      "[-1.17135861 -0.10088491  4.73339802  1.1835255   0.10402177 -0.14890975]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "(100,)\n",
      "Épisode 10/100, Reward cumulé: 3.0514224502695573\n",
      "10 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "10 1\n",
      "[-1.15796704 -0.0336094   5.10878325  0.75594398 -0.28792199 -0.62578161]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "10 2\n",
      "[-1.15528122 -0.05676956  5.09988383  0.52460601 -0.0970202   0.00549011]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "(100,)\n",
      "Épisode 11/100, Reward cumulé: 1.1755143527000458\n",
      "11 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "11 1\n",
      "[-1.02946940e+00 -4.14258436e-03  4.60271500e+00  1.65142409e-01\n",
      " -1.37598094e-02 -8.46559318e-03]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "(100,)\n",
      "11 2\n",
      "[-1.03030376e+00 -1.04766234e-02  4.60218439e+00  1.83799294e-01\n",
      " -2.26147825e-03 -1.88334186e-02]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "Épisode 12/100, Reward cumulé: 0.4420108346253485\n",
      "12 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "(100,)\n",
      "12 1\n",
      "[-1.07371945 -0.01041706  5.16946845  0.20315938 -0.01694616 -0.04538883]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "12 2\n",
      "[-1.07067980e+00 -1.70716709e-02  5.16827250e+00  2.09362422e-01\n",
      " -3.95357471e-03 -3.31009011e-02]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "Épisode 13/100, Reward cumulé: 0.4100988507035882\n",
      "13 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "(100,)\n",
      "13 1\n",
      "[-0.92739558 -0.02298725  4.44844072  0.66503731 -0.27096452  1.07452251]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "13 2\n",
      "[-0.93849348 -0.03989153  4.4853021   0.42936427 -0.12363705  0.9058985 ]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "(100,)\n",
      "Épisode 14/100, Reward cumulé: 1.209685373126392\n",
      "14 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "14 1\n",
      "[-0.74818411 -0.02995816  5.65196565  0.89276368 -0.25325171  0.63570904]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "14 2\n",
      "[-0.73010913 -0.05106164  5.67667902  0.64943766 -0.13888317  0.69835   ]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "Épisode 15/100, Reward cumulé: 1.2143285961190196\n",
      "15 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "(100,)\n",
      "15 1\n",
      "[-1.19202409 -0.01600327  4.88594088  0.33435726 -0.05360065  0.22377971]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "(100,)\n",
      "15 2\n",
      "[-1.19127003e+00 -2.46945144e-02  4.88876090e+00  2.05129943e-01\n",
      " -4.75075610e-03 -2.06536800e-02]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "(100,)\n",
      "Épisode 16/100, Reward cumulé: 0.1744487938907662\n",
      "16 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "(100,)\n",
      "16 1\n",
      "[-1.2291411  -0.02108662  3.78799184  1.01638828 -0.07874841 -0.65849363]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "(100,)\n",
      "16 2\n",
      "[-1.25537426 -0.03823175  3.76928511  0.7708523  -0.03266849 -0.4387075 ]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "Épisode 17/100, Reward cumulé: 1.555572428743522\n",
      "17 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "(100,)\n",
      "17 1\n",
      "[-0.91398298 -0.02918351  4.0532505   1.14558799 -0.21169956 -0.42286368]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "(100,)\n",
      "17 2\n",
      "[-0.94033079 -0.05409359  4.04578473  0.90213543 -0.10994101 -0.06323922]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "(100,)\n",
      "Épisode 18/100, Reward cumulé: 2.5510128209539813\n",
      "18 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "18 1\n",
      "[-1.07753788 -0.00519589  4.09556542  0.28222359 -0.11648153 -0.14806984]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "(100,)\n",
      "18 2\n",
      "[-1.08269909 -0.01041623  4.09453573  0.17664398 -0.00438655 -0.03075174]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "Épisode 19/100, Reward cumulé: 0.4117236703393334\n",
      "19 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "19 1\n",
      "[-0.83083025 -0.0237919   3.78819042  0.64989896  0.14077807  0.31345683]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "(100,)\n",
      "19 2\n",
      "[-0.84408241 -0.03672968  3.7881815   0.40242348  0.01853518 -0.16245806]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "(100,)\n",
      "Épisode 20/100, Reward cumulé: 0.7948183223747461\n",
      "20 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "20 1\n",
      "[-1.16009228 -0.03387329  5.57453018  1.06034819 -0.18877086 -1.06454281]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "(100,)\n",
      "20 2\n",
      "[-1.13809493 -0.05881356  5.54840263  0.8230893  -0.06684609 -0.50246749]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "(100,)\n",
      "Épisode 21/100, Reward cumulé: 2.06174777750274\n",
      "21 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "(100,)\n",
      "21 1\n",
      "[-1.10551275 -0.02708585  5.20435425  0.89189549  0.17712284 -1.11411842]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "21 2\n",
      "[-1.08935472 -0.04895798  5.16494447  0.64518626  0.08445671 -1.0502016 ]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "(100,)\n",
      "Épisode 22/100, Reward cumulé: 1.7022585721902512\n",
      "22 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "22 1\n",
      "[-0.86466531 -0.00954303  5.09106797  0.17731763 -0.02886638 -0.24252766]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "22 2\n",
      "[-8.62210061e-01 -1.64298317e-02  5.08858063e+00  2.13017689e-01\n",
      " -3.73135346e-03 -3.23196455e-02]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "(100,)\n",
      "Épisode 23/100, Reward cumulé: 0.20756094991231996\n",
      "23 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "(100,)\n",
      "23 1\n",
      "[-0.99449957 -0.01654916  3.80587813  0.33886265  0.15178103 -1.34705127]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "23 2\n",
      "[-1.00046444 -0.02425447  3.78009768  0.21728066  0.00693477 -0.20938404]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "Épisode 24/100, Reward cumulé: 0.7433329256123453\n",
      "24 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "(100,)\n",
      "24 1\n",
      "[-8.08073939e-01 -3.34343637e-03  4.24159216e+00  1.50063151e-01\n",
      " -7.90859499e-03 -6.40276384e-02]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "24 2\n",
      "[-8.11110764e-01 -9.05461263e-03  4.24059732e+00  1.89526641e-01\n",
      " -2.74660993e-03 -2.31285824e-02]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "(100,)\n",
      "Épisode 25/100, Reward cumulé: -0.03720982563441616\n",
      "25 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "25 1\n",
      "[-1.23704896 -0.04289444  5.37441534  1.02658186 -0.45192939  1.85229793]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "25 2\n",
      "[-1.22707196 -0.07531672  5.44256735  0.76606242 -0.30310939  1.95252363]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "(100,)\n",
      "Épisode 26/100, Reward cumulé: 1.8164949570271942\n",
      "26 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "26 1\n",
      "[-0.84842144 -0.00921141  5.18617394  0.1932239  -0.00987979 -0.08622031]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "26 2\n",
      "[-8.45135539e-01 -1.59018347e-02  5.18500898e+00  2.15009934e-01\n",
      " -2.62691949e-03 -2.23660755e-02]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "Épisode 27/100, Reward cumulé: 0.1651647352007107\n",
      "27 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "27 1\n",
      "[-0.88522071 -0.01056527  3.91011561  0.26805704 -0.01184045 -0.01320644]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "27 2\n",
      "[-8.90403591e-01 -1.52949729e-02  3.90929538e+00  1.79203326e-01\n",
      " -3.40256077e-03 -2.80908629e-02]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "(100,)\n",
      "Épisode 28/100, Reward cumulé: 0.2976531524547372\n",
      "28 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "(100,)\n",
      "28 1\n",
      "[-1.1409735  -0.00758104  4.21276944  0.13984968  0.07144204  0.25807053]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "28 2\n",
      "[-1.14350429e+00 -1.29106608e-02  4.21390844e+00  1.71612566e-01\n",
      " -2.78415260e-03 -2.29994333e-02]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "Épisode 29/100, Reward cumulé: 0.06889267176482455\n",
      "29 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "(100,)\n",
      "29 1\n",
      "[-0.87265019 -0.05315025  4.71096638  1.39098417  0.44319052 -1.70878585]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "(100,)\n",
      "29 2\n",
      "[-0.86090041 -0.09730903  4.64381869  1.11259256  0.31667197 -2.06158713]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "Épisode 30/100, Reward cumulé: 3.1052892637700915\n",
      "30 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "30 1\n",
      "[-1.15881093 -0.05354689  4.6947695   1.39257223  0.27865226 -0.65483736]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "30 2\n",
      "[-1.15263726 -0.09783436  4.66269545  1.12752175  0.16556829 -1.10996776]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "(100,)\n",
      "Épisode 31/100, Reward cumulé: 2.9639123836670085\n",
      "31 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "(100,)\n",
      "31 1\n",
      "[-1.17359819 -0.03435345  4.80057295  0.90427089  0.34554702 -1.82919256]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "31 2\n",
      "[-1.16289069 -0.06102095  4.73674217  0.65907928  0.1879735  -1.70287863]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "(100,)\n",
      "Épisode 32/100, Reward cumulé: 1.6042121541401115\n",
      "32 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "32 1\n",
      "[-1.06636656 -0.05172481  5.02839749  1.47045194  0.09353071 -1.21671252]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "(100,)\n",
      "32 2\n",
      "[-1.0498013  -0.0957624   4.98377534  1.21332732  0.08227211 -1.30532028]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "(100,)\n",
      "Épisode 33/100, Reward cumulé: 3.4865631715952157\n",
      "33 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "33 1\n",
      "[-1.1186384  -0.01289777  4.54570457  0.35136019 -0.22899623 -0.09204464]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "33 2\n",
      "[-1.12327067 -0.02134952  4.54774901  0.18718685 -0.01022171  0.0203525 ]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "(100,)\n",
      "Épisode 34/100, Reward cumulé: 0.4268432949984361\n",
      "34 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "(100,)\n",
      "34 1\n",
      "[-1.18442163 -0.04170947  5.38511949  1.06520829 -0.35209725  0.78499487]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "34 2\n",
      "[-1.17116707 -0.07345718  5.41690721  0.81840981 -0.22320592  0.95960777]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "Épisode 35/100, Reward cumulé: 2.0388934731629185\n",
      "35 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "35 1\n",
      "[-0.87748993 -0.00584043  4.81222477  0.1554502  -0.00481669 -0.01191141]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "(100,)\n",
      "35 2\n",
      "[-8.76917213e-01 -1.27234879e-02  4.81148665e+00  2.04398473e-01\n",
      " -2.99713438e-03 -2.50228228e-02]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "Épisode 36/100, Reward cumulé: 0.19523756301278905\n",
      "36 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "36 1\n",
      "[-1.10608368 -0.03988939  4.75232851  1.01150858 -0.08537405 -0.16927537]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "(100,)\n",
      "36 2\n",
      "[-1.10742058 -0.07103212  4.74675399  0.76415709 -0.05828496 -0.15159043]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "(100,)\n",
      "Épisode 37/100, Reward cumulé: 1.9738013214201195\n",
      "37 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "(100,)\n",
      "37 1\n",
      "[-1.07503607 -0.00446545  4.18474076  0.16689128 -0.00811337 -0.07265219]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "(100,)\n",
      "37 2\n",
      "[-1.07810237e+00 -9.49086951e-03  4.18369257e+00  1.68027959e-01\n",
      " -2.70307316e-03 -2.27104576e-02]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "Épisode 38/100, Reward cumulé: 0.2686033787227788\n",
      "38 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "38 1\n",
      "[-0.99130914 -0.04494331  5.28730905  1.35660014 -0.08315106 -0.04631929]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "(100,)\n",
      "38 2\n",
      "[-0.97029628 -0.08268154  5.28378034  1.10673422 -0.07541626 -0.13988768]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "Épisode 39/100, Reward cumulé: 3.2554390382238076\n",
      "39 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "39 1\n",
      "[-0.96263597 -0.02454862  4.35577614  0.51225585  0.23106684 -1.78398741]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "39 2\n",
      "[-0.96333889 -0.0401467   4.30945403  0.33960701  0.06973162 -0.79632222]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "(100,)\n",
      "Épisode 40/100, Reward cumulé: 1.0228627985669123\n",
      "40 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "(100,)\n",
      "40 1\n",
      "[-0.91886797 -0.04065342  5.48479652  1.33486509 -0.15877647  0.04798655]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "40 2\n",
      "[-0.89264755 -0.07429108  5.48775258  1.08708702 -0.1152059   0.10531562]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "(100,)\n",
      "Épisode 41/100, Reward cumulé: 2.9737000450129427\n",
      "41 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "41 1\n",
      "[-0.82905627 -0.01990109  4.74576786  0.45920549 -0.23532655  0.87929903]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "(100,)\n",
      "41 2\n",
      "[-0.83308277 -0.03242188  4.7724602   0.25084763 -0.05369749  0.46181827]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "Épisode 42/100, Reward cumulé: 0.47407653853629433\n",
      "42 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "(100,)\n",
      "42 1\n",
      "[-0.96155552 -0.01647005  4.95772047  0.38064248  0.0185504   0.19774284]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "42 2\n",
      "[-0.95913979 -0.02629507  4.95863208  0.23630313 -0.00528652 -0.03730819]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "(100,)\n",
      "Épisode 43/100, Reward cumulé: 0.7153246624937597\n",
      "43 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "43 1\n",
      "[-1.22356613 -0.04031946  5.50801062  1.11273469 -0.34929198  1.08989139]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "(100,)\n",
      "43 2\n",
      "[-1.20540197 -0.07138418  5.54914703  0.86151063 -0.23743688  1.19729517]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "(100,)\n",
      "Épisode 44/100, Reward cumulé: 2.0699600287802102\n",
      "44 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "(100,)\n",
      "44 1\n",
      "[-1.0803291  -0.00701301  5.56810924  0.41980415  0.08856893 -0.14275794]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "44 2\n",
      "[-1.07109316e+00 -1.39087414e-02  5.56192985e+00  2.68811779e-01\n",
      " -5.28970125e-03 -1.11021850e-01]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "Épisode 45/100, Reward cumulé: 0.7429705124680912\n",
      "45 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "(100,)\n",
      "45 1\n",
      "[-1.16653961 -0.02779002  3.80882214  1.46728795 -0.23983793  0.87871251]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "(100,)\n",
      "45 2\n",
      "[-1.20782744 -0.0513309   3.84080525  1.21229307 -0.20481918  0.93198773]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "Épisode 46/100, Reward cumulé: 3.0699543535793925\n",
      "46 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "46 1\n",
      "[-0.91730936 -0.03826458  4.33598729  1.22657717 -0.34394726  0.02614675]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "(100,)\n",
      "46 2\n",
      "[-0.94026651 -0.07080095  4.34492666  0.98223578 -0.21180739  0.4214596 ]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "Épisode 47/100, Reward cumulé: 2.8467937327307324\n",
      "47 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "47 1\n",
      "[-1.1386123  -0.0378143   3.9708593   1.69926615 -0.32120682 -1.03837122]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "(100,)\n",
      "47 2\n",
      "[-1.18296722 -0.07212364  3.94203495  1.46390207 -0.18892284 -0.65205567]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "(100,)\n",
      "Épisode 48/100, Reward cumulé: 3.8824099642535836\n",
      "48 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "48 1\n",
      "[-1.01328572 -0.03923799  5.08020031  1.10191272  0.04520811 -0.99100113]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "(100,)\n",
      "48 2\n",
      "[-1.00010822 -0.07082917  5.04710723  0.85294807  0.03860427 -0.88255121]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "Épisode 49/100, Reward cumulé: 2.545582427344394\n",
      "49 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "49 1\n",
      "[-8.71266126e-01  2.36421240e-03  5.53316819e+00  1.77626202e-01\n",
      "  1.40472892e-01  7.31440382e-01]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "(100,)\n",
      "49 2\n",
      "[-8.64440944e-01 -1.99018540e-03  5.54263835e+00  2.38825914e-01\n",
      "  6.99797970e-04  1.68130091e-02]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "(100,)\n",
      "Épisode 50/100, Reward cumulé: 0.29790715691339104\n",
      "50 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "50 1\n",
      "[-0.87148674 -0.00875789  4.75355347  0.20041113 -0.11615328  0.71136485]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "50 2\n",
      "[-8.72190681e-01 -1.56837543e-02  4.76188681e+00  1.96505839e-01\n",
      "  7.31392626e-04  2.06717432e-02]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "Épisode 51/100, Reward cumulé: 0.2526443312239772\n",
      "51 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "(100,)\n",
      "51 1\n",
      "[-1.24210678 -0.06140564  4.6496593   1.62141974  0.10195071 -1.26042071]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "(100,)\n",
      "51 2\n",
      "[-1.24312066 -0.11369608  4.60245034  1.36145134  0.09567757 -1.41129825]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "(100,)\n",
      "Épisode 52/100, Reward cumulé: 3.349902985137428\n",
      "52 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "52 1\n",
      "[-1.13240825 -0.01763378  4.29843694  0.50701085 -0.08221014 -0.59015082]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "52 2\n",
      "[-1.13915662 -0.02965949  4.28760785  0.28217012 -0.01202703 -0.14156057]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "(100,)\n",
      "Épisode 53/100, Reward cumulé: 0.5733978210564262\n",
      "53 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "53 1\n",
      "[-1.16319675 -0.03242167  4.53913322  0.75061153  0.23970618 -1.08252053]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "53 2\n",
      "[-1.1619391  -0.05500655  4.49988349  0.50820535  0.09374975 -1.02323441]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "Épisode 54/100, Reward cumulé: 1.1090536256255916\n",
      "54 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "54 1\n",
      "[-1.03120719 -0.01122448  5.54044698  0.42341116  0.01896625 -0.38669776]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "(100,)\n",
      "54 2\n",
      "[-1.02260031e+00 -1.88983190e-02  5.53267589e+00  2.65164243e-01\n",
      " -4.28049627e-03 -9.39733300e-02]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "Épisode 55/100, Reward cumulé: 0.8634029729126369\n",
      "55 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "55 1\n",
      "[-1.21646634 -0.02693942  4.14032679  0.6138941   0.14017119  0.60708156]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "(100,)\n",
      "55 2\n",
      "[-1.22393166 -0.04250696  4.14738069  0.36822776  0.00856204 -0.04162952]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "(100,)\n",
      "Épisode 56/100, Reward cumulé: 0.5113818082160997\n",
      "56 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "(100,)\n",
      "56 1\n",
      "[-1.11620026e+00 -7.73930813e-03  5.19577499e+00  1.80183828e-01\n",
      " -4.29512637e-03 -1.63743752e-01]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "56 2\n",
      "[-1.11298865e+00 -1.42158464e-02  5.19345206e+00  2.10420725e-01\n",
      " -5.16711776e-03 -4.42184295e-02]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "(100,)\n",
      "Épisode 57/100, Reward cumulé: 0.26185718561126137\n",
      "57 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "57 1\n",
      "[-8.35230660e-01 -1.12899883e-03  4.13789022e+00  1.64362072e-01\n",
      " -1.35185392e-02 -4.42480993e-03]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "(100,)\n",
      "57 2\n",
      "[-8.38797995e-01 -6.37073657e-03  4.13728735e+00  1.82442019e-01\n",
      " -2.63896855e-03 -2.19931430e-02]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "(100,)\n",
      "Épisode 58/100, Reward cumulé: 0.046161678763697644\n",
      "58 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "(100,)\n",
      "58 1\n",
      "[-1.02628735 -0.05302363  4.76582966  1.37333044 -0.40614082  1.25664564]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "58 2\n",
      "[-1.03524059 -0.09725319  4.81588305  1.10879847 -0.30391219  1.54931585]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "(100,)\n",
      "Épisode 59/100, Reward cumulé: 3.3445593843714936\n",
      "59 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "(100,)\n",
      "59 1\n",
      "[-8.47792515e-01 -4.67190820e-03  5.51162337e+00  1.95496534e-01\n",
      "  2.40482514e-02 -3.73257353e-01]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "(100,)\n",
      "59 2\n",
      "[-8.41814460e-01 -1.03562145e-02  5.50718118e+00  2.44699642e-01\n",
      " -4.39017375e-03 -4.49652014e-02]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "(100,)\n",
      "Épisode 60/100, Reward cumulé: 0.21189201195419013\n",
      "60 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "(100,)\n",
      "60 1\n",
      "[-0.89229385 -0.00531967  5.25111121  0.16188285 -0.00829969 -0.07597405]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "(100,)\n",
      "60 2\n",
      "[-8.88673375e-01 -1.16181068e-02  5.24996751e+00  2.15976060e-01\n",
      " -2.98205559e-03 -2.53027341e-02]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "(100,)\n",
      "Épisode 61/100, Reward cumulé: 0.2600437669249033\n",
      "61 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "61 1\n",
      "[-1.00285433 -0.03502265  4.49570285  0.96479945 -0.24840564  0.88960403]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "(100,)\n",
      "61 2\n",
      "[-1.01556426 -0.06242657  4.52829536  0.71582214 -0.15695549  0.91078282]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "Épisode 62/100, Reward cumulé: 2.1641265437688486\n",
      "62 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "(100,)\n",
      "62 1\n",
      "[-1.18632521 -0.01852499  4.50717403  0.44621183 -0.08333573  0.15024339]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "62 2\n",
      "[-1.19019533 -0.02959604  4.51115694  0.22807458 -0.01607584  0.02587755]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "Épisode 63/100, Reward cumulé: 0.3019430727986897\n",
      "63 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "(100,)\n",
      "63 1\n",
      "[-1.11658041 -0.02672508  3.83578198  0.53907311  0.29984419 -1.84150869]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "63 2\n",
      "[-1.12465515 -0.04153972  3.78209192  0.35798575  0.09789878 -1.06798685]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "(100,)\n",
      "Épisode 64/100, Reward cumulé: 0.819776668582088\n",
      "64 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "(100,)\n",
      "64 1\n",
      "[-8.89277932e-01 -7.95975820e-03  3.76021274e+00  2.05488555e-01\n",
      " -2.99537978e-03 -1.30717917e-01]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "64 2\n",
      "[-8.94611487e-01 -1.16471182e-02  3.75872968e+00  1.82951171e-01\n",
      " -2.63241050e-03 -2.24446413e-02]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "(100,)\n",
      "Épisode 65/100, Reward cumulé: 0.2337443803063721\n",
      "65 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "65 1\n",
      "[-1.05061889 -0.02307168  4.56300728  0.54917689 -0.05108128 -0.00951269]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "65 2\n",
      "[-1.05404828 -0.03777987  4.56247091  0.31546357 -0.01984727 -0.03261757]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "(100,)\n",
      "Épisode 66/100, Reward cumulé: 0.9047016245699377\n",
      "66 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "(100,)\n",
      "66 1\n",
      "[-1.00007542 -0.04060507  4.41303385  1.10599636 -0.08253111  0.20926173]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "66 2\n",
      "[-1.01279061 -0.07261784  4.41804983  0.85620434 -0.07380678  0.09386036]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "Épisode 67/100, Reward cumulé: 2.5361540796500575\n",
      "67 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "(100,)\n",
      "67 1\n",
      "[-0.89981832 -0.00999338  4.19919064  0.15993269  0.02527192  0.12959541]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "67 2\n",
      "[-9.02710840e-01 -1.52336608e-02  4.19940523e+00  1.71860387e-01\n",
      " -1.99519975e-03 -1.65761016e-02]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "Épisode 68/100, Reward cumulé: 0.2141791908152498\n",
      "68 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "68 1\n",
      "[-1.26969375 -0.05237645  4.51040886  1.50995577 -0.44567067  1.30511385]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "(100,)\n",
      "68 2\n",
      "[-1.29174659 -0.09730342  4.56316672  1.2406588  -0.34722147  1.66123353]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "Épisode 69/100, Reward cumulé: 2.9909753113636777\n",
      "69 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "(100,)\n",
      "69 1\n",
      "[-1.01980952 -0.02704355  5.50472549  0.73455387 -0.16529938 -0.24843884]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "(100,)\n",
      "69 2\n",
      "[-1.00704427 -0.04480132  5.50244601  0.49771772 -0.05932635  0.02770244]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "(100,)\n",
      "Épisode 70/100, Reward cumulé: 1.513282483807895\n",
      "70 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "(100,)\n",
      "70 1\n",
      "[-0.84185235 -0.04526953  4.07912195  1.50208789 -0.03926075 -0.83211492]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "(100,)\n",
      "70 2\n",
      "[-0.8715192  -0.08327204  4.0510877   1.25227948 -0.00805312 -0.7742935 ]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "(100,)\n",
      "Épisode 71/100, Reward cumulé: 3.3793903100591174\n",
      "71 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "71 1\n",
      "[-0.99839338 -0.02486103  4.02476866  1.0221656  -0.20113382 -0.37845533]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "71 2\n",
      "[-1.02247409 -0.04589606  4.01802986  0.78015069 -0.10398084 -0.06588713]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "Épisode 72/100, Reward cumulé: 2.2999032379522952\n",
      "72 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "72 1\n",
      "[-0.84905241 -0.03603434  4.87051751  0.86801686 -0.28306998  0.47271292]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "72 2\n",
      "[-0.85188772 -0.06301949  4.89167487  0.6258558  -0.14750004  0.64453344]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "Épisode 73/100, Reward cumulé: 1.51025821903511\n",
      "73 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "73 1\n",
      "[-1.03763229 -0.02049055  3.76758793  1.44222968 -0.35381311  0.71227084]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "(100,)\n",
      "73 2\n",
      "[-1.0809823  -0.03932079  3.79765109  1.18763098 -0.26791417  0.96440056]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "(100,)\n",
      "Épisode 74/100, Reward cumulé: 3.4193957489907154\n",
      "74 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "74 1\n",
      "[-0.85525239 -0.00538603  4.35789262  0.18067099 -0.02087272 -0.11920161]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "(100,)\n",
      "74 2\n",
      "[-8.57683317e-01 -1.14724328e-02  4.35667862e+00  1.87417259e-01\n",
      " -2.18524593e-03 -1.85064344e-02]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "(100,)\n",
      "Épisode 75/100, Reward cumulé: 0.13725013118949073\n",
      "75 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "(100,)\n",
      "75 1\n",
      "[-1.0107509  -0.02137223  4.73824032  0.48305239 -0.07067797  0.4033275 ]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "(100,)\n",
      "75 2\n",
      "[-1.0119963  -0.0343168   4.74637344  0.26341536 -0.02136531  0.07351355]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "(100,)\n",
      "Épisode 76/100, Reward cumulé: 0.9342107762442009\n",
      "76 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "(100,)\n",
      "76 1\n",
      "[-0.84367589 -0.01170489  5.33696189  0.2406681  -0.04836435  0.17184127]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "(100,)\n",
      "76 2\n",
      "[-8.39272989e-01 -1.84956400e-02  5.33801675e+00  2.29407096e-01\n",
      " -2.75282855e-03 -1.91371208e-02]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "(100,)\n",
      "Épisode 77/100, Reward cumulé: 0.22832344276419905\n",
      "77 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "(100,)\n",
      "77 1\n",
      "[-1.21006687 -0.02293724  3.85250107  0.67886487  0.08641835 -0.47527636]\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(100,)\n",
      "77 2\n",
      "[-1.22376561 -0.03675957  3.83434805  0.43156349  0.02321405 -0.46949929]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "Épisode 78/100, Reward cumulé: 0.6597635689252048\n",
      "78 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "78 1\n",
      "[-1.11021029 -0.05792769  5.11836508  1.60869022 -0.14669666 -0.2729243 ]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "(100,)\n",
      "78 2\n",
      "[-1.09409695 -0.10753211  5.10868437  1.36031263 -0.11379696 -0.28071891]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "Épisode 79/100, Reward cumulé: 3.7937794688453237\n",
      "79 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "(100,)\n",
      "79 1\n",
      "[-0.8387524  -0.04993723  4.48003741  1.24682493  0.27294502 -0.90445333]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "79 2\n",
      "[-0.84117299 -0.08958724  4.44147525  0.98505692  0.16362457 -1.22478351]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "(100,)\n",
      "Épisode 80/100, Reward cumulé: 2.555384883958034\n",
      "80 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "(100,)\n",
      "80 1\n",
      "[-0.97081791 -0.02295312  3.74614293  0.91565251  0.02751773 -0.31993226]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "(100,)\n",
      "80 2\n",
      "[-0.9933773  -0.0389687   3.73359347  0.66577137  0.00667495 -0.36057283]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "Épisode 81/100, Reward cumulé: 1.9577915084098256\n",
      "81 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "(100,)\n",
      "81 1\n",
      "[-0.9842021  -0.03685661  4.6553653   0.90689783  0.30741266 -1.57550679]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "(100,)\n",
      "81 2\n",
      "[-0.97851039 -0.06469936  4.59891308  0.65713455  0.16143479 -1.5360133 ]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "(100,)\n",
      "Épisode 82/100, Reward cumulé: 2.021846548410823\n",
      "82 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "82 1\n",
      "[-1.24736422 -0.02555848  4.6737018   0.63796861 -0.29494585  1.36425039]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "(100,)\n",
      "82 2\n",
      "[-1.25509236 -0.04369559  4.71768694  0.40949593 -0.141507    1.02860172]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "(100,)\n",
      "Épisode 83/100, Reward cumulé: 0.5995918642542339\n",
      "83 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "(100,)\n",
      "83 1\n",
      "[-1.16595524 -0.02095982  4.7745767   0.47203879 -0.2262071   0.08903941]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "83 2\n",
      "[-1.16917036 -0.03394139  4.78217365  0.26062296 -0.03903461  0.16091262]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "Épisode 84/100, Reward cumulé: 0.48681892302817026\n",
      "84 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "84 1\n",
      "[-1.00828695 -0.04898037  4.09648879  1.74649738 -0.18047467 -1.0741803 ]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "(100,)\n",
      "84 2\n",
      "[-1.04557007 -0.09220043  4.0635816   1.50347286 -0.08765433 -0.83750501]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "(100,)\n",
      "Épisode 85/100, Reward cumulé: 4.374648900664837\n",
      "85 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "(100,)\n",
      "85 1\n",
      "[-1.22924166e+00 -3.97939820e-03  4.70995746e+00  1.50195126e-01\n",
      " -6.85148158e-03 -5.85786434e-02]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "85 2\n",
      "[-1.22939773e+00 -1.02938747e-02  4.70876170e+00  1.85303806e-01\n",
      " -3.68292807e-03 -3.09529734e-02]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "Épisode 86/100, Reward cumulé: -0.16160859971876157\n",
      "86 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "(100,)\n",
      "86 1\n",
      "[-1.11299279 -0.02494993  3.69253591  1.07258547  0.05319708 -0.64494464]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "86 2\n",
      "[-1.14071439 -0.04309637  3.66831885  0.82019735  0.02705723 -0.69811407]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "(100,)\n",
      "Épisode 87/100, Reward cumulé: 2.049927262312756\n",
      "87 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "(100,)\n",
      "87 1\n",
      "[-1.12713703 -0.03753671  3.91981643  1.74228696 -0.28124723 -0.66397445]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "(100,)\n",
      "87 2\n",
      "[-1.17351926 -0.07125678  3.90140501  1.50118171 -0.18469174 -0.41890963]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "(100,)\n",
      "Épisode 88/100, Reward cumulé: 4.018405490522147\n",
      "88 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "(100,)\n",
      "88 1\n",
      "[-1.20497484e+00  1.97080509e-03  3.75027698e+00  1.88079482e-01\n",
      " -7.39026967e-02  4.53269485e-01]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "(100,)\n",
      "88 2\n",
      "[-1.20996489e+00 -6.97882152e-04  3.75332127e+00  1.55705703e-01\n",
      " -4.13943886e-03 -3.27067946e-02]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "(100,)\n",
      "Épisode 89/100, Reward cumulé: -0.11604833374879545\n",
      "89 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "(100,)\n",
      "89 1\n",
      "[-1.26882875 -0.00545327  4.01280685  0.40260278 -0.23224642  1.27772306]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "(100,)\n",
      "89 2\n",
      "[-1.27931614 -0.0106212   4.04578289  0.21026407 -0.06049404  0.48203959]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "Épisode 90/100, Reward cumulé: 0.01927507985558094\n",
      "90 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "90 1\n",
      "[-7.72416658e-01 -1.72116816e-03  5.71845779e+00  1.69746449e-01\n",
      " -7.98305492e-03 -5.53262665e-02]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "(100,)\n",
      "90 2\n",
      "[-7.65485058e-01 -6.20086394e-03  5.71785776e+00  2.57565303e-01\n",
      " -1.28238264e-03 -1.10291416e-02]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "Épisode 91/100, Reward cumulé: -0.019240357713219358\n",
      "91 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "(100,)\n",
      "91 1\n",
      "[-1.16228000e+00 -1.21733982e-03  4.27548102e+00  1.65493564e-01\n",
      " -8.11851348e-02 -7.23711548e-01]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "(100,)\n",
      "91 2\n",
      "[-1.16563774 -0.00648318  4.26794652  0.17952147 -0.00466838 -0.04193072]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "(100,)\n",
      "Épisode 92/100, Reward cumulé: 0.046910497662916495\n",
      "92 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "(100,)\n",
      "92 1\n",
      "[-1.09963722 -0.03366041  5.46093518  0.89812877 -0.2413917   0.23728868]\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "92 2\n",
      "[-1.08558323 -0.05781277  5.47302356  0.65770889 -0.12895387  0.38193567]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "(100,)\n",
      "Épisode 93/100, Reward cumulé: 1.7600272689849952\n",
      "93 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "93 1\n",
      "[-1.10037021e+00 -4.71187799e-03  5.28865971e+00  2.01458204e-01\n",
      "  5.22844185e-02 -5.67118858e-01]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "(100,)\n",
      "93 2\n",
      "[-1.09583773 -0.01118642  5.28192037  0.23000076 -0.00577737 -0.05988277]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "(100,)\n",
      "Épisode 94/100, Reward cumulé: 0.38006494659326145\n",
      "94 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(100,)\n",
      "94 1\n",
      "[-0.95018644 -0.03727824  4.86950198  1.03747397  0.39096558 -2.11110019]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "(100,)\n",
      "94 2\n",
      "[-0.93547041 -0.06738073  4.79417207  0.77839782  0.24321283 -2.09291583]\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "(100,)\n",
      "Épisode 95/100, Reward cumulé: 2.315824147835957\n",
      "95 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "(100,)\n",
      "95 1\n",
      "[-0.81461159 -0.01004043  5.25295608  0.17094535 -0.0281719   0.01553018]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "(100,)\n",
      "95 2\n",
      "[-8.11033326e-01 -1.63856006e-02  5.25310509e+00  2.13948135e-01\n",
      " -1.08945399e-03 -8.06295024e-03]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "(100,)\n",
      "Épisode 96/100, Reward cumulé: 0.044557839719370634\n",
      "96 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "(100,)\n",
      "96 1\n",
      "[-0.9324893  -0.03786896  3.9921435   1.01971351  0.25485399 -1.76478995]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(100,)\n",
      "96 2\n",
      "[-0.94834637 -0.0656959   3.93111588  0.76514236  0.16959995 -1.65129568]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "(100,)\n",
      "Épisode 97/100, Reward cumulé: 2.2216229102279885\n",
      "97 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "(100,)\n",
      "97 1\n",
      "[-1.04288674 -0.02118042  5.43303502  1.04054207  0.31656753 -2.13334563]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "(100,)\n",
      "97 2\n",
      "[-1.0156811  -0.04012708  5.35968196  0.78713481  0.20610494 -1.97572202]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "(100,)\n",
      "Épisode 98/100, Reward cumulé: 2.414070819623234\n",
      "98 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "98 1\n",
      "[-0.9032356  -0.0310877   5.11141257  0.8048226  -0.06920376 -0.17263514]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "(100,)\n",
      "98 2\n",
      "[-0.89556796 -0.05377693  5.10744099  0.56079476 -0.03292224 -0.07957955]\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "Épisode 99/100, Reward cumulé: 1.3972858743407632\n",
      "99 0\n",
      "[[-1.28179312 -0.03076161  3.81707614  1.61656511 -0.1866938  -0.35831151]]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "99 1\n",
      "[-0.93427936 -0.02071371  4.45595176  0.56525342 -0.18393986  0.62323311]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "(100,)\n",
      "99 2\n",
      "[-0.94206314 -0.03495892  4.4757419   0.33548049 -0.06283104  0.40115179]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "(100,)\n",
      "Épisode 100/100, Reward cumulé: 0.9627850126204178\n"
     ]
    }
   ],
   "source": [
    "rewards=DDPG()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbc6fbb",
   "metadata": {},
   "source": [
    "### Diagnostique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc367ae6",
   "metadata": {},
   "source": [
    "Afficher l'évolution de la moyenne des rewards cumulés calculée tous les 20 épisodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2170fc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage de la moyenne des rewards cumulés\n",
    "mean_reward=[]\n",
    "for episode in range(100):\n",
    "    if episode % 20 ==0:\n",
    "        mean_reward.append(sum(rewards[episode-20:]) / 20.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "110149aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.3387278801943252,\n",
       " 7.116534701193851,\n",
       " 5.75708157493672,\n",
       " 4.388703887071175,\n",
       " 2.881557225721894]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1727e0f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.25, 0.5 , 0.75, 1.  ])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "855be6eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "/* Put everything inside the global mpl namespace */\n/* global mpl */\nwindow.mpl = {};\n\nmpl.get_websocket_type = function () {\n    if (typeof WebSocket !== 'undefined') {\n        return WebSocket;\n    } else if (typeof MozWebSocket !== 'undefined') {\n        return MozWebSocket;\n    } else {\n        alert(\n            'Your browser does not have WebSocket support. ' +\n                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n                'Firefox 4 and 5 are also supported but you ' +\n                'have to enable WebSockets in about:config.'\n        );\n    }\n};\n\nmpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n    this.id = figure_id;\n\n    this.ws = websocket;\n\n    this.supports_binary = this.ws.binaryType !== undefined;\n\n    if (!this.supports_binary) {\n        var warnings = document.getElementById('mpl-warnings');\n        if (warnings) {\n            warnings.style.display = 'block';\n            warnings.textContent =\n                'This browser does not support binary websocket messages. ' +\n                'Performance may be slow.';\n        }\n    }\n\n    this.imageObj = new Image();\n\n    this.context = undefined;\n    this.message = undefined;\n    this.canvas = undefined;\n    this.rubberband_canvas = undefined;\n    this.rubberband_context = undefined;\n    this.format_dropdown = undefined;\n\n    this.image_mode = 'full';\n\n    this.root = document.createElement('div');\n    this.root.setAttribute('style', 'display: inline-block');\n    this._root_extra_style(this.root);\n\n    parent_element.appendChild(this.root);\n\n    this._init_header(this);\n    this._init_canvas(this);\n    this._init_toolbar(this);\n\n    var fig = this;\n\n    this.waiting = false;\n\n    this.ws.onopen = function () {\n        fig.send_message('supports_binary', { value: fig.supports_binary });\n        fig.send_message('send_image_mode', {});\n        if (fig.ratio !== 1) {\n            fig.send_message('set_device_pixel_ratio', {\n                device_pixel_ratio: fig.ratio,\n            });\n        }\n        fig.send_message('refresh', {});\n    };\n\n    this.imageObj.onload = function () {\n        if (fig.image_mode === 'full') {\n            // Full images could contain transparency (where diff images\n            // almost always do), so we need to clear the canvas so that\n            // there is no ghosting.\n            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n        }\n        fig.context.drawImage(fig.imageObj, 0, 0);\n    };\n\n    this.imageObj.onunload = function () {\n        fig.ws.close();\n    };\n\n    this.ws.onmessage = this._make_on_message_function(this);\n\n    this.ondownload = ondownload;\n};\n\nmpl.figure.prototype._init_header = function () {\n    var titlebar = document.createElement('div');\n    titlebar.classList =\n        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n    var titletext = document.createElement('div');\n    titletext.classList = 'ui-dialog-title';\n    titletext.setAttribute(\n        'style',\n        'width: 100%; text-align: center; padding: 3px;'\n    );\n    titlebar.appendChild(titletext);\n    this.root.appendChild(titlebar);\n    this.header = titletext;\n};\n\nmpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n\nmpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n\nmpl.figure.prototype._init_canvas = function () {\n    var fig = this;\n\n    var canvas_div = (this.canvas_div = document.createElement('div'));\n    canvas_div.setAttribute(\n        'style',\n        'border: 1px solid #ddd;' +\n            'box-sizing: content-box;' +\n            'clear: both;' +\n            'min-height: 1px;' +\n            'min-width: 1px;' +\n            'outline: 0;' +\n            'overflow: hidden;' +\n            'position: relative;' +\n            'resize: both;'\n    );\n\n    function on_keyboard_event_closure(name) {\n        return function (event) {\n            return fig.key_event(event, name);\n        };\n    }\n\n    canvas_div.addEventListener(\n        'keydown',\n        on_keyboard_event_closure('key_press')\n    );\n    canvas_div.addEventListener(\n        'keyup',\n        on_keyboard_event_closure('key_release')\n    );\n\n    this._canvas_extra_style(canvas_div);\n    this.root.appendChild(canvas_div);\n\n    var canvas = (this.canvas = document.createElement('canvas'));\n    canvas.classList.add('mpl-canvas');\n    canvas.setAttribute('style', 'box-sizing: content-box;');\n\n    this.context = canvas.getContext('2d');\n\n    var backingStore =\n        this.context.backingStorePixelRatio ||\n        this.context.webkitBackingStorePixelRatio ||\n        this.context.mozBackingStorePixelRatio ||\n        this.context.msBackingStorePixelRatio ||\n        this.context.oBackingStorePixelRatio ||\n        this.context.backingStorePixelRatio ||\n        1;\n\n    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n\n    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n        'canvas'\n    ));\n    rubberband_canvas.setAttribute(\n        'style',\n        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n    );\n\n    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n    if (this.ResizeObserver === undefined) {\n        if (window.ResizeObserver !== undefined) {\n            this.ResizeObserver = window.ResizeObserver;\n        } else {\n            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n            this.ResizeObserver = obs.ResizeObserver;\n        }\n    }\n\n    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n        var nentries = entries.length;\n        for (var i = 0; i < nentries; i++) {\n            var entry = entries[i];\n            var width, height;\n            if (entry.contentBoxSize) {\n                if (entry.contentBoxSize instanceof Array) {\n                    // Chrome 84 implements new version of spec.\n                    width = entry.contentBoxSize[0].inlineSize;\n                    height = entry.contentBoxSize[0].blockSize;\n                } else {\n                    // Firefox implements old version of spec.\n                    width = entry.contentBoxSize.inlineSize;\n                    height = entry.contentBoxSize.blockSize;\n                }\n            } else {\n                // Chrome <84 implements even older version of spec.\n                width = entry.contentRect.width;\n                height = entry.contentRect.height;\n            }\n\n            // Keep the size of the canvas and rubber band canvas in sync with\n            // the canvas container.\n            if (entry.devicePixelContentBoxSize) {\n                // Chrome 84 implements new version of spec.\n                canvas.setAttribute(\n                    'width',\n                    entry.devicePixelContentBoxSize[0].inlineSize\n                );\n                canvas.setAttribute(\n                    'height',\n                    entry.devicePixelContentBoxSize[0].blockSize\n                );\n            } else {\n                canvas.setAttribute('width', width * fig.ratio);\n                canvas.setAttribute('height', height * fig.ratio);\n            }\n            canvas.setAttribute(\n                'style',\n                'width: ' + width + 'px; height: ' + height + 'px;'\n            );\n\n            rubberband_canvas.setAttribute('width', width);\n            rubberband_canvas.setAttribute('height', height);\n\n            // And update the size in Python. We ignore the initial 0/0 size\n            // that occurs as the element is placed into the DOM, which should\n            // otherwise not happen due to the minimum size styling.\n            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n                fig.request_resize(width, height);\n            }\n        }\n    });\n    this.resizeObserverInstance.observe(canvas_div);\n\n    function on_mouse_event_closure(name) {\n        return function (event) {\n            return fig.mouse_event(event, name);\n        };\n    }\n\n    rubberband_canvas.addEventListener(\n        'mousedown',\n        on_mouse_event_closure('button_press')\n    );\n    rubberband_canvas.addEventListener(\n        'mouseup',\n        on_mouse_event_closure('button_release')\n    );\n    rubberband_canvas.addEventListener(\n        'dblclick',\n        on_mouse_event_closure('dblclick')\n    );\n    // Throttle sequential mouse events to 1 every 20ms.\n    rubberband_canvas.addEventListener(\n        'mousemove',\n        on_mouse_event_closure('motion_notify')\n    );\n\n    rubberband_canvas.addEventListener(\n        'mouseenter',\n        on_mouse_event_closure('figure_enter')\n    );\n    rubberband_canvas.addEventListener(\n        'mouseleave',\n        on_mouse_event_closure('figure_leave')\n    );\n\n    canvas_div.addEventListener('wheel', function (event) {\n        if (event.deltaY < 0) {\n            event.step = 1;\n        } else {\n            event.step = -1;\n        }\n        on_mouse_event_closure('scroll')(event);\n    });\n\n    canvas_div.appendChild(canvas);\n    canvas_div.appendChild(rubberband_canvas);\n\n    this.rubberband_context = rubberband_canvas.getContext('2d');\n    this.rubberband_context.strokeStyle = '#000000';\n\n    this._resize_canvas = function (width, height, forward) {\n        if (forward) {\n            canvas_div.style.width = width + 'px';\n            canvas_div.style.height = height + 'px';\n        }\n    };\n\n    // Disable right mouse context menu.\n    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n        event.preventDefault();\n        return false;\n    });\n\n    function set_focus() {\n        canvas.focus();\n        canvas_div.focus();\n    }\n\n    window.setTimeout(set_focus, 100);\n};\n\nmpl.figure.prototype._init_toolbar = function () {\n    var fig = this;\n\n    var toolbar = document.createElement('div');\n    toolbar.classList = 'mpl-toolbar';\n    this.root.appendChild(toolbar);\n\n    function on_click_closure(name) {\n        return function (_event) {\n            return fig.toolbar_button_onclick(name);\n        };\n    }\n\n    function on_mouseover_closure(tooltip) {\n        return function (event) {\n            if (!event.currentTarget.disabled) {\n                return fig.toolbar_button_onmouseover(tooltip);\n            }\n        };\n    }\n\n    fig.buttons = {};\n    var buttonGroup = document.createElement('div');\n    buttonGroup.classList = 'mpl-button-group';\n    for (var toolbar_ind in mpl.toolbar_items) {\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) {\n            /* Instead of a spacer, we start a new button group. */\n            if (buttonGroup.hasChildNodes()) {\n                toolbar.appendChild(buttonGroup);\n            }\n            buttonGroup = document.createElement('div');\n            buttonGroup.classList = 'mpl-button-group';\n            continue;\n        }\n\n        var button = (fig.buttons[name] = document.createElement('button'));\n        button.classList = 'mpl-widget';\n        button.setAttribute('role', 'button');\n        button.setAttribute('aria-disabled', 'false');\n        button.addEventListener('click', on_click_closure(method_name));\n        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n\n        var icon_img = document.createElement('img');\n        icon_img.src = '_images/' + image + '.png';\n        icon_img.srcset = '_images/' + image + '_large.png 2x';\n        icon_img.alt = tooltip;\n        button.appendChild(icon_img);\n\n        buttonGroup.appendChild(button);\n    }\n\n    if (buttonGroup.hasChildNodes()) {\n        toolbar.appendChild(buttonGroup);\n    }\n\n    var fmt_picker = document.createElement('select');\n    fmt_picker.classList = 'mpl-widget';\n    toolbar.appendChild(fmt_picker);\n    this.format_dropdown = fmt_picker;\n\n    for (var ind in mpl.extensions) {\n        var fmt = mpl.extensions[ind];\n        var option = document.createElement('option');\n        option.selected = fmt === mpl.default_extension;\n        option.innerHTML = fmt;\n        fmt_picker.appendChild(option);\n    }\n\n    var status_bar = document.createElement('span');\n    status_bar.classList = 'mpl-message';\n    toolbar.appendChild(status_bar);\n    this.message = status_bar;\n};\n\nmpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n    // which will in turn request a refresh of the image.\n    this.send_message('resize', { width: x_pixels, height: y_pixels });\n};\n\nmpl.figure.prototype.send_message = function (type, properties) {\n    properties['type'] = type;\n    properties['figure_id'] = this.id;\n    this.ws.send(JSON.stringify(properties));\n};\n\nmpl.figure.prototype.send_draw_message = function () {\n    if (!this.waiting) {\n        this.waiting = true;\n        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n    }\n};\n\nmpl.figure.prototype.handle_save = function (fig, _msg) {\n    var format_dropdown = fig.format_dropdown;\n    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n    fig.ondownload(fig, format);\n};\n\nmpl.figure.prototype.handle_resize = function (fig, msg) {\n    var size = msg['size'];\n    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n        fig._resize_canvas(size[0], size[1], msg['forward']);\n        fig.send_message('refresh', {});\n    }\n};\n\nmpl.figure.prototype.handle_rubberband = function (fig, msg) {\n    var x0 = msg['x0'] / fig.ratio;\n    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n    var x1 = msg['x1'] / fig.ratio;\n    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n    x0 = Math.floor(x0) + 0.5;\n    y0 = Math.floor(y0) + 0.5;\n    x1 = Math.floor(x1) + 0.5;\n    y1 = Math.floor(y1) + 0.5;\n    var min_x = Math.min(x0, x1);\n    var min_y = Math.min(y0, y1);\n    var width = Math.abs(x1 - x0);\n    var height = Math.abs(y1 - y0);\n\n    fig.rubberband_context.clearRect(\n        0,\n        0,\n        fig.canvas.width / fig.ratio,\n        fig.canvas.height / fig.ratio\n    );\n\n    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n};\n\nmpl.figure.prototype.handle_figure_label = function (fig, msg) {\n    // Updates the figure title.\n    fig.header.textContent = msg['label'];\n};\n\nmpl.figure.prototype.handle_cursor = function (fig, msg) {\n    fig.rubberband_canvas.style.cursor = msg['cursor'];\n};\n\nmpl.figure.prototype.handle_message = function (fig, msg) {\n    fig.message.textContent = msg['message'];\n};\n\nmpl.figure.prototype.handle_draw = function (fig, _msg) {\n    // Request the server to send over a new figure.\n    fig.send_draw_message();\n};\n\nmpl.figure.prototype.handle_image_mode = function (fig, msg) {\n    fig.image_mode = msg['mode'];\n};\n\nmpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n    for (var key in msg) {\n        if (!(key in fig.buttons)) {\n            continue;\n        }\n        fig.buttons[key].disabled = !msg[key];\n        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n    }\n};\n\nmpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n    if (msg['mode'] === 'PAN') {\n        fig.buttons['Pan'].classList.add('active');\n        fig.buttons['Zoom'].classList.remove('active');\n    } else if (msg['mode'] === 'ZOOM') {\n        fig.buttons['Pan'].classList.remove('active');\n        fig.buttons['Zoom'].classList.add('active');\n    } else {\n        fig.buttons['Pan'].classList.remove('active');\n        fig.buttons['Zoom'].classList.remove('active');\n    }\n};\n\nmpl.figure.prototype.updated_canvas_event = function () {\n    // Called whenever the canvas gets updated.\n    this.send_message('ack', {});\n};\n\n// A function to construct a web socket function for onmessage handling.\n// Called in the figure constructor.\nmpl.figure.prototype._make_on_message_function = function (fig) {\n    return function socket_on_message(evt) {\n        if (evt.data instanceof Blob) {\n            var img = evt.data;\n            if (img.type !== 'image/png') {\n                /* FIXME: We get \"Resource interpreted as Image but\n                 * transferred with MIME type text/plain:\" errors on\n                 * Chrome.  But how to set the MIME type?  It doesn't seem\n                 * to be part of the websocket stream */\n                img.type = 'image/png';\n            }\n\n            /* Free the memory for the previous frames */\n            if (fig.imageObj.src) {\n                (window.URL || window.webkitURL).revokeObjectURL(\n                    fig.imageObj.src\n                );\n            }\n\n            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n                img\n            );\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        } else if (\n            typeof evt.data === 'string' &&\n            evt.data.slice(0, 21) === 'data:image/png;base64'\n        ) {\n            fig.imageObj.src = evt.data;\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        }\n\n        var msg = JSON.parse(evt.data);\n        var msg_type = msg['type'];\n\n        // Call the  \"handle_{type}\" callback, which takes\n        // the figure and JSON message as its only arguments.\n        try {\n            var callback = fig['handle_' + msg_type];\n        } catch (e) {\n            console.log(\n                \"No handler for the '\" + msg_type + \"' message type: \",\n                msg\n            );\n            return;\n        }\n\n        if (callback) {\n            try {\n                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n                callback(fig, msg);\n            } catch (e) {\n                console.log(\n                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n                    e,\n                    e.stack,\n                    msg\n                );\n            }\n        }\n    };\n};\n\n// from https://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\nmpl.findpos = function (e) {\n    //this section is from http://www.quirksmode.org/js/events_properties.html\n    var targ;\n    if (!e) {\n        e = window.event;\n    }\n    if (e.target) {\n        targ = e.target;\n    } else if (e.srcElement) {\n        targ = e.srcElement;\n    }\n    if (targ.nodeType === 3) {\n        // defeat Safari bug\n        targ = targ.parentNode;\n    }\n\n    // pageX,Y are the mouse positions relative to the document\n    var boundingRect = targ.getBoundingClientRect();\n    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n\n    return { x: x, y: y };\n};\n\n/*\n * return a copy of an object with only non-object keys\n * we need this to avoid circular references\n * https://stackoverflow.com/a/24161582/3208463\n */\nfunction simpleKeys(original) {\n    return Object.keys(original).reduce(function (obj, key) {\n        if (typeof original[key] !== 'object') {\n            obj[key] = original[key];\n        }\n        return obj;\n    }, {});\n}\n\nmpl.figure.prototype.mouse_event = function (event, name) {\n    var canvas_pos = mpl.findpos(event);\n\n    if (name === 'button_press') {\n        this.canvas.focus();\n        this.canvas_div.focus();\n    }\n\n    var x = canvas_pos.x * this.ratio;\n    var y = canvas_pos.y * this.ratio;\n\n    this.send_message(name, {\n        x: x,\n        y: y,\n        button: event.button,\n        step: event.step,\n        guiEvent: simpleKeys(event),\n    });\n\n    /* This prevents the web browser from automatically changing to\n     * the text insertion cursor when the button is pressed.  We want\n     * to control all of the cursor setting manually through the\n     * 'cursor' event from matplotlib */\n    event.preventDefault();\n    return false;\n};\n\nmpl.figure.prototype._key_event_extra = function (_event, _name) {\n    // Handle any extra behaviour associated with a key event\n};\n\nmpl.figure.prototype.key_event = function (event, name) {\n    // Prevent repeat events\n    if (name === 'key_press') {\n        if (event.key === this._key) {\n            return;\n        } else {\n            this._key = event.key;\n        }\n    }\n    if (name === 'key_release') {\n        this._key = null;\n    }\n\n    var value = '';\n    if (event.ctrlKey && event.key !== 'Control') {\n        value += 'ctrl+';\n    }\n    else if (event.altKey && event.key !== 'Alt') {\n        value += 'alt+';\n    }\n    else if (event.shiftKey && event.key !== 'Shift') {\n        value += 'shift+';\n    }\n\n    value += 'k' + event.key;\n\n    this._key_event_extra(event, name);\n\n    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n    return false;\n};\n\nmpl.figure.prototype.toolbar_button_onclick = function (name) {\n    if (name === 'download') {\n        this.handle_save(this, null);\n    } else {\n        this.send_message('toolbar_button', { name: name });\n    }\n};\n\nmpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n    this.message.textContent = tooltip;\n};\n\n///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n// prettier-ignore\nvar _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\nmpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n\nmpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n\nmpl.default_extension = \"png\";/* global mpl */\n\nvar comm_websocket_adapter = function (comm) {\n    // Create a \"websocket\"-like object which calls the given IPython comm\n    // object with the appropriate methods. Currently this is a non binary\n    // socket, so there is still some room for performance tuning.\n    var ws = {};\n\n    ws.binaryType = comm.kernel.ws.binaryType;\n    ws.readyState = comm.kernel.ws.readyState;\n    function updateReadyState(_event) {\n        if (comm.kernel.ws) {\n            ws.readyState = comm.kernel.ws.readyState;\n        } else {\n            ws.readyState = 3; // Closed state.\n        }\n    }\n    comm.kernel.ws.addEventListener('open', updateReadyState);\n    comm.kernel.ws.addEventListener('close', updateReadyState);\n    comm.kernel.ws.addEventListener('error', updateReadyState);\n\n    ws.close = function () {\n        comm.close();\n    };\n    ws.send = function (m) {\n        //console.log('sending', m);\n        comm.send(m);\n    };\n    // Register the callback with on_msg.\n    comm.on_msg(function (msg) {\n        //console.log('receiving', msg['content']['data'], msg);\n        var data = msg['content']['data'];\n        if (data['blob'] !== undefined) {\n            data = {\n                data: new Blob(msg['buffers'], { type: data['blob'] }),\n            };\n        }\n        // Pass the mpl event to the overridden (by mpl) onmessage function.\n        ws.onmessage(data);\n    });\n    return ws;\n};\n\nmpl.mpl_figure_comm = function (comm, msg) {\n    // This is the function which gets called when the mpl process\n    // starts-up an IPython Comm through the \"matplotlib\" channel.\n\n    var id = msg.content.data.id;\n    // Get hold of the div created by the display call when the Comm\n    // socket was opened in Python.\n    var element = document.getElementById(id);\n    var ws_proxy = comm_websocket_adapter(comm);\n\n    function ondownload(figure, _format) {\n        window.open(figure.canvas.toDataURL());\n    }\n\n    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n\n    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n    // web socket which is closed, not our websocket->open comm proxy.\n    ws_proxy.onopen();\n\n    fig.parent_element = element;\n    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n    if (!fig.cell_info) {\n        console.error('Failed to find cell for figure', id, fig);\n        return;\n    }\n    fig.cell_info[0].output_area.element.on(\n        'cleared',\n        { fig: fig },\n        fig._remove_fig_handler\n    );\n};\n\nmpl.figure.prototype.handle_close = function (fig, msg) {\n    var width = fig.canvas.width / fig.ratio;\n    fig.cell_info[0].output_area.element.off(\n        'cleared',\n        fig._remove_fig_handler\n    );\n    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n\n    // Update the output cell to use the data from the current canvas.\n    fig.push_to_output();\n    var dataURL = fig.canvas.toDataURL();\n    // Re-enable the keyboard manager in IPython - without this line, in FF,\n    // the notebook keyboard shortcuts fail.\n    IPython.keyboard_manager.enable();\n    fig.parent_element.innerHTML =\n        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n    fig.close_ws(fig, msg);\n};\n\nmpl.figure.prototype.close_ws = function (fig, msg) {\n    fig.send_message('closing', msg);\n    // fig.ws.close()\n};\n\nmpl.figure.prototype.push_to_output = function (_remove_interactive) {\n    // Turn the data on the canvas into data in the output cell.\n    var width = this.canvas.width / this.ratio;\n    var dataURL = this.canvas.toDataURL();\n    this.cell_info[1]['text/html'] =\n        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n};\n\nmpl.figure.prototype.updated_canvas_event = function () {\n    // Tell IPython that the notebook contents must change.\n    IPython.notebook.set_dirty(true);\n    this.send_message('ack', {});\n    var fig = this;\n    // Wait a second, then push the new image to the DOM so\n    // that it is saved nicely (might be nice to debounce this).\n    setTimeout(function () {\n        fig.push_to_output();\n    }, 1000);\n};\n\nmpl.figure.prototype._init_toolbar = function () {\n    var fig = this;\n\n    var toolbar = document.createElement('div');\n    toolbar.classList = 'btn-toolbar';\n    this.root.appendChild(toolbar);\n\n    function on_click_closure(name) {\n        return function (_event) {\n            return fig.toolbar_button_onclick(name);\n        };\n    }\n\n    function on_mouseover_closure(tooltip) {\n        return function (event) {\n            if (!event.currentTarget.disabled) {\n                return fig.toolbar_button_onmouseover(tooltip);\n            }\n        };\n    }\n\n    fig.buttons = {};\n    var buttonGroup = document.createElement('div');\n    buttonGroup.classList = 'btn-group';\n    var button;\n    for (var toolbar_ind in mpl.toolbar_items) {\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) {\n            /* Instead of a spacer, we start a new button group. */\n            if (buttonGroup.hasChildNodes()) {\n                toolbar.appendChild(buttonGroup);\n            }\n            buttonGroup = document.createElement('div');\n            buttonGroup.classList = 'btn-group';\n            continue;\n        }\n\n        button = fig.buttons[name] = document.createElement('button');\n        button.classList = 'btn btn-default';\n        button.href = '#';\n        button.title = name;\n        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n        button.addEventListener('click', on_click_closure(method_name));\n        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n        buttonGroup.appendChild(button);\n    }\n\n    if (buttonGroup.hasChildNodes()) {\n        toolbar.appendChild(buttonGroup);\n    }\n\n    // Add the status bar.\n    var status_bar = document.createElement('span');\n    status_bar.classList = 'mpl-message pull-right';\n    toolbar.appendChild(status_bar);\n    this.message = status_bar;\n\n    // Add the close button to the window.\n    var buttongrp = document.createElement('div');\n    buttongrp.classList = 'btn-group inline pull-right';\n    button = document.createElement('button');\n    button.classList = 'btn btn-mini btn-primary';\n    button.href = '#';\n    button.title = 'Stop Interaction';\n    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n    button.addEventListener('click', function (_evt) {\n        fig.handle_close(fig, {});\n    });\n    button.addEventListener(\n        'mouseover',\n        on_mouseover_closure('Stop Interaction')\n    );\n    buttongrp.appendChild(button);\n    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n};\n\nmpl.figure.prototype._remove_fig_handler = function (event) {\n    var fig = event.data.fig;\n    if (event.target !== this) {\n        // Ignore bubbled events from children.\n        return;\n    }\n    fig.close_ws(fig, {});\n};\n\nmpl.figure.prototype._root_extra_style = function (el) {\n    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n};\n\nmpl.figure.prototype._canvas_extra_style = function (el) {\n    // this is important to make the div 'focusable\n    el.setAttribute('tabindex', 0);\n    // reach out to IPython and tell the keyboard manager to turn it's self\n    // off when our div gets focus\n\n    // location in version 3\n    if (IPython.notebook.keyboard_manager) {\n        IPython.notebook.keyboard_manager.register_events(el);\n    } else {\n        // location in version 2\n        IPython.keyboard_manager.register_events(el);\n    }\n};\n\nmpl.figure.prototype._key_event_extra = function (event, _name) {\n    // Check for shift+enter\n    if (event.shiftKey && event.which === 13) {\n        this.canvas_div.blur();\n        // select the cell after this one\n        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n        IPython.notebook.select(index + 1);\n    }\n};\n\nmpl.figure.prototype.handle_save = function (fig, _msg) {\n    fig.ondownload(fig, null);\n};\n\nmpl.find_output_cell = function (html_output) {\n    // Return the cell and output element which can be found *uniquely* in the notebook.\n    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n    // IPython event is triggered only after the cells have been serialised, which for\n    // our purposes (turning an active figure into a static one), is too late.\n    var cells = IPython.notebook.get_cells();\n    var ncells = cells.length;\n    for (var i = 0; i < ncells; i++) {\n        var cell = cells[i];\n        if (cell.cell_type === 'code') {\n            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n                var data = cell.output_area.outputs[j];\n                if (data.data) {\n                    // IPython >= 3 moved mimebundle to data attribute of output\n                    data = data.data;\n                }\n                if (data['text/html'] === html_output) {\n                    return [cell, data, j];\n                }\n            }\n        }\n    }\n};\n\n// Register the function which deals with the matplotlib target/channel.\n// The kernel may be null if the page has been refreshed.\nif (IPython.notebook.kernel !== null) {\n    IPython.notebook.kernel.comm_manager.register_target(\n        'matplotlib',\n        mpl.mpl_figure_comm\n    );\n}\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id='4792ca2a-d316-4c49-b3f1-158c7d0cceb3'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x=np.linspace(0,100,5)\n",
    "plt.plot(x,mean_reward)\n",
    "plt.savefig(\"resultasts3.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bad3e6",
   "metadata": {},
   "source": [
    "### Réglage des paramètres d'apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f40573",
   "metadata": {},
   "source": [
    "Essayer différents paramètres utilisés lors de l'apprentissage ainsi que différentes architecture de réseaux de neurones. Comment pourrait-on automatiser une recherche intelligente de cesdivers paramètres?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8102ff6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests et évaluation avec différentes configurations\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "michelin2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
